{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f849722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "from keras import backend\n",
    "from keras import layers\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.engine import training\n",
    "from keras.utils import data_utils\n",
    "from keras.utils import layer_utils\n",
    "import tensorflow.compat.v2 as tf\n",
    "# pylint: disable=g-direct-tensorflow-import\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@keras_export(\"keras.applications.efficientnet_v2.decode_predictions\")\n",
    "def decode_predictions(preds, top=5):\n",
    "  return imagenet_utils.decode_predictions(preds, top=top)\n",
    "\n",
    "\n",
    "decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EfficientNetV2M(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    "):\n",
    "  return EfficientNetV2(\n",
    "      width_coefficient=1.0,\n",
    "      depth_coefficient=1.0,\n",
    "      default_size=480,\n",
    "      model_name=\"efficientnetv2-m\",\n",
    "      include_top=include_top,\n",
    "      weights=weights,\n",
    "      input_tensor=input_tensor,\n",
    "      input_shape=input_shape,\n",
    "      pooling=pooling,\n",
    "      classes=classes,\n",
    "      classifier_activation=classifier_activation,\n",
    "      include_preprocessing=include_preprocessing,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf65398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:37.606014Z",
     "iopub.status.busy": "2022-04-10T19:52:37.604415Z",
     "iopub.status.idle": "2022-04-10T19:52:43.105464Z",
     "shell.execute_reply": "2022-04-10T19:52:43.106001Z",
     "shell.execute_reply.started": "2022-04-10T19:38:28.428417Z"
    },
    "papermill": {
     "duration": 5.525787,
     "end_time": "2022-04-10T19:52:43.106302",
     "exception": false,
     "start_time": "2022-04-10T19:52:37.580515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b39bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:43.141895Z",
     "iopub.status.busy": "2022-04-10T19:52:43.141064Z",
     "iopub.status.idle": "2022-04-10T19:52:49.378671Z",
     "shell.execute_reply": "2022-04-10T19:52:49.378184Z",
     "shell.execute_reply.started": "2022-04-10T19:38:33.685996Z"
    },
    "papermill": {
     "duration": 6.256491,
     "end_time": "2022-04-10T19:52:49.378813",
     "exception": false,
     "start_time": "2022-04-10T19:52:43.122322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a98291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:49.420309Z",
     "iopub.status.busy": "2022-04-10T19:52:49.419745Z",
     "iopub.status.idle": "2022-04-10T19:52:49.939844Z",
     "shell.execute_reply": "2022-04-10T19:52:49.939264Z",
     "shell.execute_reply.started": "2022-04-10T19:38:39.819090Z"
    },
    "papermill": {
     "duration": 0.54344,
     "end_time": "2022-04-10T19:52:49.940000",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.396560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [300, 300]\n",
    "# GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4fb11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:49.977290Z",
     "iopub.status.busy": "2022-04-10T19:52:49.976696Z",
     "iopub.status.idle": "2022-04-10T19:52:49.979593Z",
     "shell.execute_reply": "2022-04-10T19:52:49.979042Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.329131Z"
    },
    "papermill": {
     "duration": 0.023532,
     "end_time": "2022-04-10T19:52:49.979721",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.956189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c36a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.019156Z",
     "iopub.status.busy": "2022-04-10T19:52:50.014234Z",
     "iopub.status.idle": "2022-04-10T19:52:50.021327Z",
     "shell.execute_reply": "2022-04-10T19:52:50.020762Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.335269Z"
    },
    "papermill": {
     "duration": 0.025848,
     "end_time": "2022-04-10T19:52:50.021466",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.995618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'boneage': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'male': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    boneAge = tf.cast(example['boneage'], tf.int32)\n",
    "    male = tf.cast(example['male'], tf.bool)\n",
    "    inputs = {}\n",
    "    inputs['image'] = image\n",
    "    inputs['gender'] = male\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f47ced4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.056587Z",
     "iopub.status.busy": "2022-04-10T19:52:50.056031Z",
     "iopub.status.idle": "2022-04-10T19:52:50.060245Z",
     "shell.execute_reply": "2022-04-10T19:52:50.060687Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.345223Z"
    },
    "papermill": {
     "duration": 0.023319,
     "end_time": "2022-04-10T19:52:50.060828",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.037509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b82e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.096130Z",
     "iopub.status.busy": "2022-04-10T19:52:50.095514Z",
     "iopub.status.idle": "2022-04-10T19:52:50.190549Z",
     "shell.execute_reply": "2022-04-10T19:52:50.191001Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.353761Z"
    },
    "papermill": {
     "duration": 0.114837,
     "end_time": "2022-04-10T19:52:50.191167",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.076330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    # tf.io.gfile.glob(GCS_PATH + '/bone_age_tfrecords/*.tfrec'),\n",
    "    tf.io.gfile.glob('../bone-age-tfrecords/*.tfrec'),\n",
    "    test_size=0.2, random_state=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f004b021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.226775Z",
     "iopub.status.busy": "2022-04-10T19:52:50.226196Z",
     "iopub.status.idle": "2022-04-10T19:52:50.244194Z",
     "shell.execute_reply": "2022-04-10T19:52:50.243692Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.456897Z"
    },
    "papermill": {
     "duration": 0.037242,
     "end_time": "2022-04-10T19:52:50.244331",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.207089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_data_augment(inputs, boneAge):\n",
    "    image = inputs['image']\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    # p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, HEIGHT, shear=20.)\n",
    "        else:\n",
    "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    # if p_pixel_1 >= .4:\n",
    "    #     image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    inputs['image'] = image\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c631d672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.282425Z",
     "iopub.status.busy": "2022-04-10T19:52:50.281779Z",
     "iopub.status.idle": "2022-04-10T19:52:50.301863Z",
     "shell.execute_reply": "2022-04-10T19:52:50.302481Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.476951Z"
    },
    "papermill": {
     "duration": 0.041691,
     "end_time": "2022-04-10T19:52:50.302655",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.260964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1850b105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.352714Z",
     "iopub.status.busy": "2022-04-10T19:52:50.351786Z",
     "iopub.status.idle": "2022-04-10T19:52:50.355739Z",
     "shell.execute_reply": "2022-04-10T19:52:50.356342Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.500638Z"
    },
    "papermill": {
     "duration": 0.034942,
     "end_time": "2022-04-10T19:52:50.356507",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.321565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)  \n",
    "    dataset = dataset.map(custom_data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a990c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.401347Z",
     "iopub.status.busy": "2022-04-10T19:52:50.399000Z",
     "iopub.status.idle": "2022-04-10T19:52:50.403466Z",
     "shell.execute_reply": "2022-04-10T19:52:50.404084Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.510367Z"
    },
    "papermill": {
     "duration": 0.028805,
     "end_time": "2022-04-10T19:52:50.404236",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.375431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5331569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.442253Z",
     "iopub.status.busy": "2022-04-10T19:52:50.441652Z",
     "iopub.status.idle": "2022-04-10T19:52:50.446098Z",
     "shell.execute_reply": "2022-04-10T19:52:50.446622Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.518842Z"
    },
    "papermill": {
     "duration": 0.025189,
     "end_time": "2022-04-10T19:52:50.446775",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.421586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c95ff237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.489102Z",
     "iopub.status.busy": "2022-04-10T19:52:50.488134Z",
     "iopub.status.idle": "2022-04-10T19:52:50.494803Z",
     "shell.execute_reply": "2022-04-10T19:52:50.496020Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.530532Z"
    },
    "papermill": {
     "duration": 0.028672,
     "end_time": "2022-04-10T19:52:50.496321",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.467649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10088 training images, 2523 validation images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a5ce9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.541580Z",
     "iopub.status.busy": "2022-04-10T19:52:50.540945Z",
     "iopub.status.idle": "2022-04-10T19:52:50.547705Z",
     "shell.execute_reply": "2022-04-10T19:52:50.548296Z",
     "shell.execute_reply.started": "2022-04-10T19:49:03.261704Z"
    },
    "papermill": {
     "duration": 0.031482,
     "end_time": "2022-04-10T19:52:50.548598",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.517116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestLr = 0.0107977516232771\n",
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=20)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "optimizer = Adam(learning_rate = bestLr, beta_1 = 0.9, beta_2 = 0.999, epsilon = 0.1)\n",
    "callBacks = [early, reduceLROnPlat, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18171c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.595607Z",
     "iopub.status.busy": "2022-04-10T19:52:50.589415Z",
     "iopub.status.idle": "2022-04-10T19:53:03.670097Z",
     "shell.execute_reply": "2022-04-10T19:53:03.670560Z",
     "shell.execute_reply.started": "2022-04-10T19:49:06.282767Z"
    },
    "papermill": {
     "duration": 13.102513,
     "end_time": "2022-04-10T19:53:03.670745",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.568232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():       \n",
    "    i1 = Input(shape=(300, 300, 1), name='image')\n",
    "    i2 = Input(shape=(1), name='gender')\n",
    "    base = EfficientNetV2M(input_tensor=i1, input_shape=(300, 300, 1), include_top=False, weights=None)\n",
    "\n",
    "    feature_img = base.output\n",
    "    feature_img = Flatten()(feature_img)\n",
    "    feature_gender = Dense(32, activation='relu')(i2)\n",
    "    feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "    o = Dense(1000, activation='relu')(feature)\n",
    "    o = Dense(1000, activation='relu')(o)\n",
    "    o = Dense(1)(o)\n",
    "    model = Model(inputs=[i1, i2], outputs=o)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf460843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:03.710143Z",
     "iopub.status.busy": "2022-04-10T19:53:03.709464Z",
     "iopub.status.idle": "2022-04-10T19:53:05.667706Z",
     "shell.execute_reply": "2022-04-10T19:53:05.668227Z",
     "shell.execute_reply.started": "2022-04-10T19:49:26.522923Z"
    },
    "papermill": {
     "duration": 1.981459,
     "end_time": "2022-04-10T19:53:05.668389",
     "exception": false,
     "start_time": "2022-04-10T19:53:03.686930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset()\n",
    "valid_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52e50287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:05.707462Z",
     "iopub.status.busy": "2022-04-10T19:53:05.706616Z",
     "iopub.status.idle": "2022-04-10T19:53:05.709501Z",
     "shell.execute_reply": "2022-04-10T19:53:05.708967Z",
     "shell.execute_reply.started": "2022-04-10T19:49:29.682510Z"
    },
    "papermill": {
     "duration": 0.024051,
     "end_time": "2022-04-10T19:53:05.709633",
     "exception": false,
     "start_time": "2022-04-10T19:53:05.685582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184864b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:05.751000Z",
     "iopub.status.busy": "2022-04-10T19:53:05.750227Z",
     "iopub.status.idle": "2022-04-10T23:21:33.471137Z",
     "shell.execute_reply": "2022-04-10T23:21:33.470510Z",
     "shell.execute_reply.started": "2022-04-10T19:49:34.380025Z"
    },
    "papermill": {
     "duration": 12507.74575,
     "end_time": "2022-04-10T23:21:33.471335",
     "exception": false,
     "start_time": "2022-04-10T19:53:05.725585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 40.3689 - mae: 40.3689\n",
      "Epoch 1: val_loss improved from inf to 32.45477, saving model to bone_age_weights.best.hdf5\n",
      "1261/1261 [==============================] - 665s 487ms/step - loss: 40.3689 - mae: 40.3689 - val_loss: 32.4548 - val_mae: 32.4548 - lr: 0.0108\n",
      "Epoch 2/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 34.7066 - mae: 34.7066\n",
      "Epoch 2: val_loss improved from 32.45477 to 31.62196, saving model to bone_age_weights.best.hdf5\n",
      "1261/1261 [==============================] - 600s 476ms/step - loss: 34.7066 - mae: 34.7066 - val_loss: 31.6220 - val_mae: 31.6220 - lr: 0.0108\n",
      "Epoch 3/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 33.2827 - mae: 33.2827\n",
      "Epoch 3: val_loss did not improve from 31.62196\n",
      "1261/1261 [==============================] - 574s 455ms/step - loss: 33.2827 - mae: 33.2827 - val_loss: 32.4310 - val_mae: 32.4310 - lr: 0.0108\n",
      "Epoch 4/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 33.0271 - mae: 33.0271\n",
      "Epoch 4: val_loss did not improve from 31.62196\n",
      "1261/1261 [==============================] - 575s 456ms/step - loss: 33.0271 - mae: 33.0271 - val_loss: 31.9558 - val_mae: 31.9558 - lr: 0.0108\n",
      "Epoch 5/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.6534 - mae: 32.6534\n",
      "Epoch 5: val_loss improved from 31.62196 to 31.37911, saving model to bone_age_weights.best.hdf5\n",
      "1261/1261 [==============================] - 583s 462ms/step - loss: 32.6534 - mae: 32.6534 - val_loss: 31.3791 - val_mae: 31.3791 - lr: 0.0108\n",
      "Epoch 6/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.6281 - mae: 32.6281\n",
      "Epoch 6: val_loss improved from 31.37911 to 31.00819, saving model to bone_age_weights.best.hdf5\n",
      "1261/1261 [==============================] - 600s 476ms/step - loss: 32.6281 - mae: 32.6281 - val_loss: 31.0082 - val_mae: 31.0082 - lr: 0.0108\n",
      "Epoch 7/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.5009 - mae: 32.5009\n",
      "Epoch 7: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 595s 471ms/step - loss: 32.5009 - mae: 32.5009 - val_loss: 32.1915 - val_mae: 32.1915 - lr: 0.0108\n",
      "Epoch 8/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.3523 - mae: 32.3523\n",
      "Epoch 8: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 592s 469ms/step - loss: 32.3523 - mae: 32.3523 - val_loss: 31.8468 - val_mae: 31.8468 - lr: 0.0108\n",
      "Epoch 9/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.5001 - mae: 32.5001\n",
      "Epoch 9: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 559s 444ms/step - loss: 32.5001 - mae: 32.5001 - val_loss: 32.3002 - val_mae: 32.3002 - lr: 0.0108\n",
      "Epoch 10/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.1799 - mae: 32.1799\n",
      "Epoch 10: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 553s 438ms/step - loss: 32.1799 - mae: 32.1799 - val_loss: 31.2375 - val_mae: 31.2375 - lr: 0.0108\n",
      "Epoch 11/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.5332 - mae: 32.5332\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.008638201653957367.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.5332 - mae: 32.5332 - val_loss: 31.6000 - val_mae: 31.6000 - lr: 0.0108\n",
      "Epoch 12/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.0251 - mae: 32.0251\n",
      "Epoch 12: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.0251 - mae: 32.0251 - val_loss: 31.2278 - val_mae: 31.2278 - lr: 0.0086\n",
      "Epoch 13/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.0090 - mae: 32.0090\n",
      "Epoch 13: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.0090 - mae: 32.0090 - val_loss: 31.2484 - val_mae: 31.2484 - lr: 0.0086\n",
      "Epoch 14/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.1138 - mae: 32.1138\n",
      "Epoch 14: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 553s 438ms/step - loss: 32.1138 - mae: 32.1138 - val_loss: 32.6054 - val_mae: 32.6054 - lr: 0.0086\n",
      "Epoch 15/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.0867 - mae: 32.0867\n",
      "Epoch 15: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 553s 438ms/step - loss: 32.0867 - mae: 32.0867 - val_loss: 31.5375 - val_mae: 31.5375 - lr: 0.0086\n",
      "Epoch 16/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.2113 - mae: 32.2113\n",
      "Epoch 16: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.2113 - mae: 32.2113 - val_loss: 31.1029 - val_mae: 31.1029 - lr: 0.0086\n",
      "Epoch 17/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.1643 - mae: 32.1643\n",
      "Epoch 17: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 553s 439ms/step - loss: 32.1643 - mae: 32.1643 - val_loss: 31.8925 - val_mae: 31.8925 - lr: 0.0086\n",
      "Epoch 18/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.2625 - mae: 32.2625\n",
      "Epoch 18: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.2625 - mae: 32.2625 - val_loss: 31.5997 - val_mae: 31.5997 - lr: 0.0086\n",
      "Epoch 19/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.1304 - mae: 32.1304\n",
      "Epoch 19: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.1304 - mae: 32.1304 - val_loss: 31.1116 - val_mae: 31.1116 - lr: 0.0086\n",
      "Epoch 20/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.9749 - mae: 31.9749\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00691056102514267.\n",
      "\n",
      "Epoch 20: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 31.9749 - mae: 31.9749 - val_loss: 31.3113 - val_mae: 31.3113 - lr: 0.0086\n",
      "Epoch 21/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 32.0146 - mae: 32.0146\n",
      "Epoch 21: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 32.0146 - mae: 32.0146 - val_loss: 32.8361 - val_mae: 32.8361 - lr: 0.0069\n",
      "Epoch 22/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.9170 - mae: 31.9170\n",
      "Epoch 22: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 31.9170 - mae: 31.9170 - val_loss: 32.8597 - val_mae: 32.8597 - lr: 0.0069\n",
      "Epoch 23/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.9812 - mae: 31.9812\n",
      "Epoch 23: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 31.9812 - mae: 31.9812 - val_loss: 31.2863 - val_mae: 31.2863 - lr: 0.0069\n",
      "Epoch 24/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.8335 - mae: 31.8335\n",
      "Epoch 24: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 551s 437ms/step - loss: 31.8335 - mae: 31.8335 - val_loss: 32.5036 - val_mae: 32.5036 - lr: 0.0069\n",
      "Epoch 25/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.9464 - mae: 31.9464\n",
      "Epoch 25: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 551s 437ms/step - loss: 31.9464 - mae: 31.9464 - val_loss: 31.6543 - val_mae: 31.6543 - lr: 0.0069\n",
      "Epoch 26/250\n",
      "1261/1261 [==============================] - ETA: 0s - loss: 31.9345 - mae: 31.9345\n",
      "Epoch 26: val_loss did not improve from 31.00819\n",
      "1261/1261 [==============================] - 552s 438ms/step - loss: 31.9345 - mae: 31.9345 - val_loss: 32.0493 - val_mae: 32.0493 - lr: 0.0069\n"
     ]
    }
   ],
   "source": [
    "initalHistory = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=250,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks = callBacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78bcbf71713dd947ce2131f7f6689fb7d7a7279f673cc1a06b2b5cdb722ee962"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('newEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12552.345905,
   "end_time": "2022-04-10T23:21:42.488841",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-10T19:52:30.142936",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
