{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cdcffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:20.036911Z",
     "iopub.status.busy": "2022-04-08T21:10:20.035092Z",
     "iopub.status.idle": "2022-04-08T21:10:26.757665Z",
     "shell.execute_reply": "2022-04-08T21:10:26.758232Z",
     "shell.execute_reply.started": "2022-04-08T18:53:10.783496Z"
    },
    "papermill": {
     "duration": 6.746686,
     "end_time": "2022-04-08T21:10:26.758552",
     "exception": false,
     "start_time": "2022-04-08T21:10:20.011866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 21:10:21.769492: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-04-08 21:10:21.769642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dense, Dropout, Input, Conv2D, multiply, LocallyConnected2D, Lambda, BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.metrics import mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91a06a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:26.800705Z",
     "iopub.status.busy": "2022-04-08T21:10:26.799692Z",
     "iopub.status.idle": "2022-04-08T21:10:31.945722Z",
     "shell.execute_reply": "2022-04-08T21:10:31.944519Z",
     "shell.execute_reply.started": "2022-04-08T18:52:25.672245Z"
    },
    "papermill": {
     "duration": 5.167943,
     "end_time": "2022-04-08T21:10:31.945900",
     "exception": false,
     "start_time": "2022-04-08T21:10:26.777957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: grpc://10.0.0.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 21:10:26.806763: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-08 21:10:26.809466: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-04-08 21:10:26.809506: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-08 21:10:26.809532: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e3002ed5a47f): /proc/driver/nvidia/version does not exist\n",
      "2022-04-08 21:10:26.812280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-08 21:10:26.813536: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-08 21:10:26.845045: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-04-08 21:10:26.845147: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-04-08 21:10:26.869696: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-04-08 21:10:26.869756: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-04-08 21:10:26.871278: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c41e3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:31.997905Z",
     "iopub.status.busy": "2022-04-08T21:10:31.997186Z",
     "iopub.status.idle": "2022-04-08T21:10:32.349490Z",
     "shell.execute_reply": "2022-04-08T21:10:32.348920Z",
     "shell.execute_reply.started": "2022-04-08T18:52:33.638632Z"
    },
    "papermill": {
     "duration": 0.38417,
     "end_time": "2022-04-08T21:10:32.349695",
     "exception": false,
     "start_time": "2022-04-08T21:10:31.965525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [512, 512]\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd42bdc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.392748Z",
     "iopub.status.busy": "2022-04-08T21:10:32.389588Z",
     "iopub.status.idle": "2022-04-08T21:10:32.395847Z",
     "shell.execute_reply": "2022-04-08T21:10:32.395220Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.082993Z"
    },
    "papermill": {
     "duration": 0.027716,
     "end_time": "2022-04-08T21:10:32.395994",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.368278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "#     image = tf.image.rgb_to_grayscale(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f6f2a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.441859Z",
     "iopub.status.busy": "2022-04-08T21:10:32.440988Z",
     "iopub.status.idle": "2022-04-08T21:10:32.444098Z",
     "shell.execute_reply": "2022-04-08T21:10:32.443482Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.091064Z"
    },
    "papermill": {
     "duration": 0.029431,
     "end_time": "2022-04-08T21:10:32.444252",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.414821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "#         'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'boneage': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'male': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    boneAge = tf.cast(example['boneage'], tf.int32)\n",
    "    # male = tf.cast(example['male'], tf.bool)\n",
    "    # inputs = {}\n",
    "    # inputs['image'] = image\n",
    "    # inputs['gender'] = male\n",
    "    # return inputs, boneAge\n",
    "    return image, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3e50ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.485884Z",
     "iopub.status.busy": "2022-04-08T21:10:32.485170Z",
     "iopub.status.idle": "2022-04-08T21:10:32.489910Z",
     "shell.execute_reply": "2022-04-08T21:10:32.490422Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.103686Z"
    },
    "papermill": {
     "duration": 0.027515,
     "end_time": "2022-04-08T21:10:32.490627",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.463112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec01fc83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.532743Z",
     "iopub.status.busy": "2022-04-08T21:10:32.531976Z",
     "iopub.status.idle": "2022-04-08T21:10:32.635356Z",
     "shell.execute_reply": "2022-04-08T21:10:32.634649Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.118337Z"
    },
    "papermill": {
     "duration": 0.125462,
     "end_time": "2022-04-08T21:10:32.635502",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.510040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 21:10:32.538714: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    tf.io.gfile.glob(GCS_PATH + '/bone_age_tfrecords/*.tfrec'),\n",
    "    # tf.io.gfile.glob('./bone-age-tfrecords/*.tfrec'),\n",
    "    test_size=0.2, random_state=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1ab22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.694442Z",
     "iopub.status.busy": "2022-04-08T21:10:32.693490Z",
     "iopub.status.idle": "2022-04-08T21:10:32.696384Z",
     "shell.execute_reply": "2022-04-08T21:10:32.695877Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.207197Z"
    },
    "papermill": {
     "duration": 0.041988,
     "end_time": "2022-04-08T21:10:32.696533",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.654545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_data_augment(image, boneAge):\n",
    "    # image = inputs['image']\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, HEIGHT, shear=20.)\n",
    "        else:\n",
    "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
    "        \n",
    "#     # Pixel-level transforms\n",
    "#     if p_pixel_1 >= .4:\n",
    "#         image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    # inputs['image'] = image\n",
    "    return image, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e16c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.756691Z",
     "iopub.status.busy": "2022-04-08T21:10:32.737836Z",
     "iopub.status.idle": "2022-04-08T21:10:32.759114Z",
     "shell.execute_reply": "2022-04-08T21:10:32.759700Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.228944Z"
    },
    "papermill": {
     "duration": 0.044341,
     "end_time": "2022-04-08T21:10:32.759875",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.715534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78e39fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.801111Z",
     "iopub.status.busy": "2022-04-08T21:10:32.800438Z",
     "iopub.status.idle": "2022-04-08T21:10:32.805689Z",
     "shell.execute_reply": "2022-04-08T21:10:32.806365Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.252730Z"
    },
    "papermill": {
     "duration": 0.027676,
     "end_time": "2022-04-08T21:10:32.806543",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.778867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)  \n",
    "    dataset = dataset.map(custom_data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f100e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.851764Z",
     "iopub.status.busy": "2022-04-08T21:10:32.851038Z",
     "iopub.status.idle": "2022-04-08T21:10:32.853115Z",
     "shell.execute_reply": "2022-04-08T21:10:32.853683Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.269514Z"
    },
    "papermill": {
     "duration": 0.027207,
     "end_time": "2022-04-08T21:10:32.853864",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.826657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bf2952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.895008Z",
     "iopub.status.busy": "2022-04-08T21:10:32.894320Z",
     "iopub.status.idle": "2022-04-08T21:10:32.899326Z",
     "shell.execute_reply": "2022-04-08T21:10:32.899874Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.280398Z"
    },
    "papermill": {
     "duration": 0.02712,
     "end_time": "2022-04-08T21:10:32.900047",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.872927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8ce6b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.944999Z",
     "iopub.status.busy": "2022-04-08T21:10:32.942166Z",
     "iopub.status.idle": "2022-04-08T21:10:32.949163Z",
     "shell.execute_reply": "2022-04-08T21:10:32.948533Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.293707Z"
    },
    "papermill": {
     "duration": 0.029501,
     "end_time": "2022-04-08T21:10:32.949308",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.919807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10088 training images, 2523 validation images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561e8295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:32.992123Z",
     "iopub.status.busy": "2022-04-08T21:10:32.991148Z",
     "iopub.status.idle": "2022-04-08T21:10:32.998361Z",
     "shell.execute_reply": "2022-04-08T21:10:32.998866Z",
     "shell.execute_reply.started": "2022-04-08T18:53:16.339824Z"
    },
    "papermill": {
     "duration": 0.030224,
     "end_time": "2022-04-08T21:10:32.999062",
     "exception": false,
     "start_time": "2022-04-08T21:10:32.968838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestLr = 0.0107977516232771\n",
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=20)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "\n",
    "optimizer = Adam(learning_rate = bestLr)\n",
    "callBacks = [early, reduceLROnPlat, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9841fd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:33.042276Z",
     "iopub.status.busy": "2022-04-08T21:10:33.041194Z",
     "iopub.status.idle": "2022-04-08T21:10:33.045286Z",
     "shell.execute_reply": "2022-04-08T21:10:33.045794Z",
     "shell.execute_reply.started": "2022-04-08T18:53:19.797808Z"
    },
    "papermill": {
     "duration": 0.027502,
     "end_time": "2022-04-08T21:10:33.045974",
     "exception": false,
     "start_time": "2022-04-08T21:10:33.018472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mae_months(in_gt, in_pred):\n",
    "        return mean_absolute_error(1 * in_gt, 1 * in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69250305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:33.088592Z",
     "iopub.status.busy": "2022-04-08T21:10:33.087592Z",
     "iopub.status.idle": "2022-04-08T21:10:36.112901Z",
     "shell.execute_reply": "2022-04-08T21:10:36.113513Z",
     "shell.execute_reply.started": "2022-04-08T19:01:15.611323Z"
    },
    "papermill": {
     "duration": 3.048477,
     "end_time": "2022-04-08T21:10:36.113722",
     "exception": false,
     "start_time": "2022-04-08T21:10:33.065245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():       \n",
    "    \n",
    "    in_lay = Input(shape=(512, 512, 1))\n",
    "    base_pretrained_model = VGG16(input_shape =  (512, 512, 1), include_top = False, weights = None)\n",
    "    pt_features = base_pretrained_model(in_lay)\n",
    "    pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "    bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "    # here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "\n",
    "    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "    attn_layer = LocallyConnected2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "    # fan it out to all of the channels\n",
    "    up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "#     up_c2_w = np.ones((1, pt_depth))\n",
    "    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "    up_c2.trainable = False\n",
    "    attn_layer = up_c2(attn_layer)\n",
    "\n",
    "    mask_features = multiply([attn_layer, bn_features])\n",
    "    gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "    gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "    # to account for missing values from the attention model\n",
    "    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "    gap_dr = Dropout(0.5)(gap)\n",
    "    dr_steps = Dropout(0.25)(Dense(1024, activation = 'elu')(gap_dr))\n",
    "    out_layer = Dense(1, activation = 'linear')(dr_steps) # linear is what 16bit did\n",
    "    model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = 'mean_absolute_error', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d231f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:36.158497Z",
     "iopub.status.busy": "2022-04-08T21:10:36.157559Z",
     "iopub.status.idle": "2022-04-08T21:10:36.160204Z",
     "shell.execute_reply": "2022-04-08T21:10:36.159651Z",
     "shell.execute_reply.started": "2022-04-08T18:52:34.679843Z"
    },
    "papermill": {
     "duration": 0.026799,
     "end_time": "2022-04-08T21:10:36.160375",
     "exception": false,
     "start_time": "2022-04-08T21:10:36.133576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcca51f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:36.209348Z",
     "iopub.status.busy": "2022-04-08T21:10:36.208575Z",
     "iopub.status.idle": "2022-04-08T21:10:38.055362Z",
     "shell.execute_reply": "2022-04-08T21:10:38.054628Z",
     "shell.execute_reply.started": "2022-04-08T18:53:29.663297Z"
    },
    "papermill": {
     "duration": 1.87557,
     "end_time": "2022-04-08T21:10:38.055508",
     "exception": false,
     "start_time": "2022-04-08T21:10:36.179938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset()\n",
    "valid_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a139753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:38.099346Z",
     "iopub.status.busy": "2022-04-08T21:10:38.098342Z",
     "iopub.status.idle": "2022-04-08T21:10:38.102415Z",
     "shell.execute_reply": "2022-04-08T21:10:38.102924Z",
     "shell.execute_reply.started": "2022-04-08T19:01:22.960398Z"
    },
    "papermill": {
     "duration": 0.028095,
     "end_time": "2022-04-08T21:10:38.103102",
     "exception": false,
     "start_time": "2022-04-08T21:10:38.075007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26729666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T21:10:38.147271Z",
     "iopub.status.busy": "2022-04-08T21:10:38.146213Z",
     "iopub.status.idle": "2022-04-08T21:22:18.632473Z",
     "shell.execute_reply": "2022-04-08T21:22:18.631911Z"
    },
    "papermill": {
     "duration": 700.509206,
     "end_time": "2022-04-08T21:22:18.632649",
     "exception": false,
     "start_time": "2022-04-08T21:10:38.123443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "78/78 [==============================] - 77s 533ms/step - loss: 58.0384 - mae: 58.0384 - val_loss: 136.0800 - val_mae: 136.0800\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 136.08005, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 2/250\n",
      "78/78 [==============================] - 31s 392ms/step - loss: 34.0126 - mae: 34.0126 - val_loss: 9503632.0000 - val_mae: 9503632.0000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 136.08005\n",
      "Epoch 3/250\n",
      "78/78 [==============================] - 32s 412ms/step - loss: 33.7252 - mae: 33.7252 - val_loss: 230.1591 - val_mae: 230.1591\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 136.08005\n",
      "Epoch 4/250\n",
      "78/78 [==============================] - 30s 387ms/step - loss: 33.6498 - mae: 33.6498 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 136.08005\n",
      "Epoch 5/250\n",
      "78/78 [==============================] - 32s 415ms/step - loss: 33.7028 - mae: 33.7028 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 136.08005\n",
      "Epoch 6/250\n",
      "78/78 [==============================] - 30s 388ms/step - loss: 33.2905 - mae: 33.2905 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.008638201653957367.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 136.08005\n",
      "Epoch 7/250\n",
      "78/78 [==============================] - 32s 414ms/step - loss: 33.4316 - mae: 33.4316 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 136.08005\n",
      "Epoch 8/250\n",
      "78/78 [==============================] - 29s 375ms/step - loss: 33.5747 - mae: 33.5747 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 136.08005\n",
      "Epoch 9/250\n",
      "78/78 [==============================] - 32s 412ms/step - loss: 33.3923 - mae: 33.3923 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 136.08005\n",
      "Epoch 10/250\n",
      "78/78 [==============================] - 30s 383ms/step - loss: 33.2961 - mae: 33.2961 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 136.08005\n",
      "Epoch 11/250\n",
      "78/78 [==============================] - 32s 413ms/step - loss: 33.3075 - mae: 33.3075 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 136.08005\n",
      "Epoch 12/250\n",
      "78/78 [==============================] - 29s 376ms/step - loss: 33.1149 - mae: 33.1149 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 136.08005\n",
      "Epoch 13/250\n",
      "78/78 [==============================] - 32s 417ms/step - loss: 33.6327 - mae: 33.6327 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 136.08005\n",
      "Epoch 14/250\n",
      "78/78 [==============================] - 29s 377ms/step - loss: 33.2617 - mae: 33.2617 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 136.08005\n",
      "Epoch 15/250\n",
      "78/78 [==============================] - 32s 416ms/step - loss: 33.4195 - mae: 33.4195 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00691056102514267.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 136.08005\n",
      "Epoch 16/250\n",
      "78/78 [==============================] - 28s 362ms/step - loss: 33.0251 - mae: 33.0251 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 136.08005\n",
      "Epoch 17/250\n",
      "78/78 [==============================] - 33s 420ms/step - loss: 33.4937 - mae: 33.4937 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 136.08005\n",
      "Epoch 18/250\n",
      "78/78 [==============================] - 28s 359ms/step - loss: 33.5231 - mae: 33.5231 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 136.08005\n",
      "Epoch 19/250\n",
      "78/78 [==============================] - 33s 425ms/step - loss: 33.1591 - mae: 33.1591 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 136.08005\n",
      "Epoch 20/250\n",
      "78/78 [==============================] - 32s 414ms/step - loss: 33.1696 - mae: 33.1696 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 136.08005\n",
      "Epoch 21/250\n",
      "78/78 [==============================] - 32s 411ms/step - loss: 33.5214 - mae: 33.5214 - val_loss: nan - val_mae: nan\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 136.08005\n"
     ]
    }
   ],
   "source": [
    "initalHistory = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    # epochs=3,\n",
    "                    epochs = 250,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks = callBacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 731.151802,
   "end_time": "2022-04-08T21:22:22.395583",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-08T21:10:11.243781",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
