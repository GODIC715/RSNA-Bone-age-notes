{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf65398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:37.606014Z",
     "iopub.status.busy": "2022-04-10T19:52:37.604415Z",
     "iopub.status.idle": "2022-04-10T19:52:43.105464Z",
     "shell.execute_reply": "2022-04-10T19:52:43.106001Z",
     "shell.execute_reply.started": "2022-04-10T19:38:28.428417Z"
    },
    "papermill": {
     "duration": 5.525787,
     "end_time": "2022-04-10T19:52:43.106302",
     "exception": false,
     "start_time": "2022-04-10T19:52:37.580515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17124/2992022789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# from kaggle_datasets import KaggleDatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0muser_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tensorflow\\python\\tpu\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_embedding_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_embedding_v2_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tensorflow\\python\\tpu\\tpu_embedding_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_embedding_v2_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtpu_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python39\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b39bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:43.141895Z",
     "iopub.status.busy": "2022-04-10T19:52:43.141064Z",
     "iopub.status.idle": "2022-04-10T19:52:49.378671Z",
     "shell.execute_reply": "2022-04-10T19:52:49.378184Z",
     "shell.execute_reply.started": "2022-04-10T19:38:33.685996Z"
    },
    "papermill": {
     "duration": 6.256491,
     "end_time": "2022-04-10T19:52:49.378813",
     "exception": false,
     "start_time": "2022-04-10T19:52:43.122322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a98291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:49.420309Z",
     "iopub.status.busy": "2022-04-10T19:52:49.419745Z",
     "iopub.status.idle": "2022-04-10T19:52:49.939844Z",
     "shell.execute_reply": "2022-04-10T19:52:49.939264Z",
     "shell.execute_reply.started": "2022-04-10T19:38:39.819090Z"
    },
    "papermill": {
     "duration": 0.54344,
     "end_time": "2022-04-10T19:52:49.940000",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.396560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [600, 600]\n",
    "# GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "HEIGHT = IMAGE_SIZE[0]\n",
    "WIDTH = IMAGE_SIZE[1]\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4fb11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:49.977290Z",
     "iopub.status.busy": "2022-04-10T19:52:49.976696Z",
     "iopub.status.idle": "2022-04-10T19:52:49.979593Z",
     "shell.execute_reply": "2022-04-10T19:52:49.979042Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.329131Z"
    },
    "papermill": {
     "duration": 0.023532,
     "end_time": "2022-04-10T19:52:49.979721",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.956189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c36a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.019156Z",
     "iopub.status.busy": "2022-04-10T19:52:50.014234Z",
     "iopub.status.idle": "2022-04-10T19:52:50.021327Z",
     "shell.execute_reply": "2022-04-10T19:52:50.020762Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.335269Z"
    },
    "papermill": {
     "duration": 0.025848,
     "end_time": "2022-04-10T19:52:50.021466",
     "exception": false,
     "start_time": "2022-04-10T19:52:49.995618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'boneage': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'male': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    boneAge = tf.cast(example['boneage'], tf.int32)\n",
    "    male = tf.cast(example['male'], tf.bool)\n",
    "    inputs = {}\n",
    "    inputs['image'] = image\n",
    "    inputs['gender'] = male\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f47ced4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.056587Z",
     "iopub.status.busy": "2022-04-10T19:52:50.056031Z",
     "iopub.status.idle": "2022-04-10T19:52:50.060245Z",
     "shell.execute_reply": "2022-04-10T19:52:50.060687Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.345223Z"
    },
    "papermill": {
     "duration": 0.023319,
     "end_time": "2022-04-10T19:52:50.060828",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.037509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b82e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.096130Z",
     "iopub.status.busy": "2022-04-10T19:52:50.095514Z",
     "iopub.status.idle": "2022-04-10T19:52:50.190549Z",
     "shell.execute_reply": "2022-04-10T19:52:50.191001Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.353761Z"
    },
    "papermill": {
     "duration": 0.114837,
     "end_time": "2022-04-10T19:52:50.191167",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.076330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    # tf.io.gfile.glob(GCS_PATH + '/bone_age_tfrecords/*.tfrec'),\n",
    "    tf.io.gfile.glob('../bone-age-tfrecords/*.tfrec'),\n",
    "    test_size=0.2, random_state=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f004b021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.226775Z",
     "iopub.status.busy": "2022-04-10T19:52:50.226196Z",
     "iopub.status.idle": "2022-04-10T19:52:50.244194Z",
     "shell.execute_reply": "2022-04-10T19:52:50.243692Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.456897Z"
    },
    "papermill": {
     "duration": 0.037242,
     "end_time": "2022-04-10T19:52:50.244331",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.207089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_data_augment(inputs, boneAge):\n",
    "    image = inputs['image']\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    # p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, HEIGHT, shear=20.)\n",
    "        else:\n",
    "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270º\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180º\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90º\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    # if p_pixel_1 >= .4:\n",
    "    #     image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    inputs['image'] = image\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c631d672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.282425Z",
     "iopub.status.busy": "2022-04-10T19:52:50.281779Z",
     "iopub.status.idle": "2022-04-10T19:52:50.301863Z",
     "shell.execute_reply": "2022-04-10T19:52:50.302481Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.476951Z"
    },
    "papermill": {
     "duration": 0.041691,
     "end_time": "2022-04-10T19:52:50.302655",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.260964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1850b105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.352714Z",
     "iopub.status.busy": "2022-04-10T19:52:50.351786Z",
     "iopub.status.idle": "2022-04-10T19:52:50.355739Z",
     "shell.execute_reply": "2022-04-10T19:52:50.356342Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.500638Z"
    },
    "papermill": {
     "duration": 0.034942,
     "end_time": "2022-04-10T19:52:50.356507",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.321565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)  \n",
    "    dataset = dataset.map(custom_data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a990c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.401347Z",
     "iopub.status.busy": "2022-04-10T19:52:50.399000Z",
     "iopub.status.idle": "2022-04-10T19:52:50.403466Z",
     "shell.execute_reply": "2022-04-10T19:52:50.404084Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.510367Z"
    },
    "papermill": {
     "duration": 0.028805,
     "end_time": "2022-04-10T19:52:50.404236",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.375431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5331569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.442253Z",
     "iopub.status.busy": "2022-04-10T19:52:50.441652Z",
     "iopub.status.idle": "2022-04-10T19:52:50.446098Z",
     "shell.execute_reply": "2022-04-10T19:52:50.446622Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.518842Z"
    },
    "papermill": {
     "duration": 0.025189,
     "end_time": "2022-04-10T19:52:50.446775",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.421586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95ff237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.489102Z",
     "iopub.status.busy": "2022-04-10T19:52:50.488134Z",
     "iopub.status.idle": "2022-04-10T19:52:50.494803Z",
     "shell.execute_reply": "2022-04-10T19:52:50.496020Z",
     "shell.execute_reply.started": "2022-04-10T19:38:40.530532Z"
    },
    "papermill": {
     "duration": 0.028672,
     "end_time": "2022-04-10T19:52:50.496321",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.467649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10088 training images, 2523 validation images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5ce9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.541580Z",
     "iopub.status.busy": "2022-04-10T19:52:50.540945Z",
     "iopub.status.idle": "2022-04-10T19:52:50.547705Z",
     "shell.execute_reply": "2022-04-10T19:52:50.548296Z",
     "shell.execute_reply.started": "2022-04-10T19:49:03.261704Z"
    },
    "papermill": {
     "duration": 0.031482,
     "end_time": "2022-04-10T19:52:50.548598",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.517116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestLr = 0.0107977516232771\n",
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=20)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "optimizer = Adam(learning_rate = bestLr, beta_1 = 0.9, beta_2 = 0.999, epsilon = 0.1)\n",
    "callBacks = [early, reduceLROnPlat, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18171c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:52:50.595607Z",
     "iopub.status.busy": "2022-04-10T19:52:50.589415Z",
     "iopub.status.idle": "2022-04-10T19:53:03.670097Z",
     "shell.execute_reply": "2022-04-10T19:53:03.670560Z",
     "shell.execute_reply.started": "2022-04-10T19:49:06.282767Z"
    },
    "papermill": {
     "duration": 13.102513,
     "end_time": "2022-04-10T19:53:03.670745",
     "exception": false,
     "start_time": "2022-04-10T19:52:50.568232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():       \n",
    "    i1 = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), name='image')\n",
    "    i2 = Input(shape=(1), name='gender')\n",
    "    base = InceptionV3(input_tensor=i1, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), include_top=False, weights=None)\n",
    "\n",
    "    feature_img = base.get_layer(name='mixed10').output\n",
    "    feature_img = AveragePooling2D((2, 2))(feature_img)\n",
    "    feature_img = Flatten()(feature_img)\n",
    "    feature_gender = Dense(32, activation='relu')(i2)\n",
    "    feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "    o = Dense(1000, activation='relu')(feature)\n",
    "    o = Dense(1000, activation='relu')(o)\n",
    "    o = Dense(1)(o)\n",
    "    model = Model(inputs=[i1, i2], outputs=o)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf460843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:03.710143Z",
     "iopub.status.busy": "2022-04-10T19:53:03.709464Z",
     "iopub.status.idle": "2022-04-10T19:53:05.667706Z",
     "shell.execute_reply": "2022-04-10T19:53:05.668227Z",
     "shell.execute_reply.started": "2022-04-10T19:49:26.522923Z"
    },
    "papermill": {
     "duration": 1.981459,
     "end_time": "2022-04-10T19:53:05.668389",
     "exception": false,
     "start_time": "2022-04-10T19:53:03.686930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset()\n",
    "valid_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e50287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:05.707462Z",
     "iopub.status.busy": "2022-04-10T19:53:05.706616Z",
     "iopub.status.idle": "2022-04-10T19:53:05.709501Z",
     "shell.execute_reply": "2022-04-10T19:53:05.708967Z",
     "shell.execute_reply.started": "2022-04-10T19:49:29.682510Z"
    },
    "papermill": {
     "duration": 0.024051,
     "end_time": "2022-04-10T19:53:05.709633",
     "exception": false,
     "start_time": "2022-04-10T19:53:05.685582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184864b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T19:53:05.751000Z",
     "iopub.status.busy": "2022-04-10T19:53:05.750227Z",
     "iopub.status.idle": "2022-04-10T23:21:33.471137Z",
     "shell.execute_reply": "2022-04-10T23:21:33.470510Z",
     "shell.execute_reply.started": "2022-04-10T19:49:34.380025Z"
    },
    "papermill": {
     "duration": 12507.74575,
     "end_time": "2022-04-10T23:21:33.471335",
     "exception": false,
     "start_time": "2022-04-10T19:53:05.725585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 39.4177 - mae: 39.4177\n",
      "Epoch 00001: val_loss improved from inf to 52.85956, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 457s 679ms/step - loss: 39.4177 - mae: 39.4177 - val_loss: 52.8596 - val_mae: 52.8596 - lr: 0.0108\n",
      "Epoch 2/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 34.9066 - mae: 34.9066\n",
      "Epoch 00002: val_loss improved from 52.85956 to 37.29735, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 425s 674ms/step - loss: 34.9066 - mae: 34.9066 - val_loss: 37.2974 - val_mae: 37.2974 - lr: 0.0108\n",
      "Epoch 3/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 34.5664 - mae: 34.5664\n",
      "Epoch 00003: val_loss improved from 37.29735 to 32.56194, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 424s 673ms/step - loss: 34.5664 - mae: 34.5664 - val_loss: 32.5619 - val_mae: 32.5619 - lr: 0.0108\n",
      "Epoch 4/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 33.9293 - mae: 33.9293\n",
      "Epoch 00004: val_loss improved from 32.56194 to 31.18168, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 419s 666ms/step - loss: 33.9293 - mae: 33.9293 - val_loss: 31.1817 - val_mae: 31.1817 - lr: 0.0108\n",
      "Epoch 5/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.7770 - mae: 32.7770\n",
      "Epoch 00005: val_loss improved from 31.18168 to 30.72874, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 418s 664ms/step - loss: 32.7770 - mae: 32.7770 - val_loss: 30.7287 - val_mae: 30.7287 - lr: 0.0108\n",
      "Epoch 6/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.7053 - mae: 31.7053\n",
      "Epoch 00006: val_loss did not improve from 30.72874\n",
      "630/630 [==============================] - 411s 652ms/step - loss: 31.7053 - mae: 31.7053 - val_loss: 32.2814 - val_mae: 32.2814 - lr: 0.0108\n",
      "Epoch 7/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.1802 - mae: 32.1802\n",
      "Epoch 00007: val_loss did not improve from 30.72874\n",
      "630/630 [==============================] - 411s 652ms/step - loss: 32.1802 - mae: 32.1802 - val_loss: 31.8544 - val_mae: 31.8544 - lr: 0.0108\n",
      "Epoch 8/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.4326 - mae: 32.4326\n",
      "Epoch 00008: val_loss improved from 30.72874 to 29.54737, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 419s 664ms/step - loss: 32.4326 - mae: 32.4326 - val_loss: 29.5474 - val_mae: 29.5474 - lr: 0.0108\n",
      "Epoch 9/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.3051 - mae: 32.3051\n",
      "Epoch 00009: val_loss did not improve from 29.54737\n",
      "630/630 [==============================] - 412s 653ms/step - loss: 32.3051 - mae: 32.3051 - val_loss: 34.2799 - val_mae: 34.2799 - lr: 0.0108\n",
      "Epoch 10/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.7860 - mae: 31.7860\n",
      "Epoch 00010: val_loss did not improve from 29.54737\n",
      "630/630 [==============================] - 410s 651ms/step - loss: 31.7860 - mae: 31.7860 - val_loss: 31.1719 - val_mae: 31.1719 - lr: 0.0108\n",
      "Epoch 11/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.4192 - mae: 32.4192\n",
      "Epoch 00011: val_loss did not improve from 29.54737\n",
      "630/630 [==============================] - 385s 612ms/step - loss: 32.4192 - mae: 32.4192 - val_loss: 34.8500 - val_mae: 34.8500 - lr: 0.0108\n",
      "Epoch 12/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.4829 - mae: 31.4829\n",
      "Epoch 00012: val_loss did not improve from 29.54737\n",
      "630/630 [==============================] - 377s 598ms/step - loss: 31.4829 - mae: 31.4829 - val_loss: 35.1937 - val_mae: 35.1937 - lr: 0.0108\n",
      "Epoch 13/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.7067 - mae: 31.7067\n",
      "Epoch 00013: val_loss improved from 29.54737 to 29.16525, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 384s 610ms/step - loss: 31.7067 - mae: 31.7067 - val_loss: 29.1653 - val_mae: 29.1653 - lr: 0.0108\n",
      "Epoch 14/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.1591 - mae: 31.1591\n",
      "Epoch 00014: val_loss did not improve from 29.16525\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 31.1591 - mae: 31.1591 - val_loss: 30.6140 - val_mae: 30.6140 - lr: 0.0108\n",
      "Epoch 15/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.7334 - mae: 30.7334\n",
      "Epoch 00015: val_loss improved from 29.16525 to 28.67182, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 613ms/step - loss: 30.7334 - mae: 30.7334 - val_loss: 28.6718 - val_mae: 28.6718 - lr: 0.0108\n",
      "Epoch 16/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.7515 - mae: 30.7515\n",
      "Epoch 00016: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 30.7515 - mae: 30.7515 - val_loss: 28.9074 - val_mae: 28.9074 - lr: 0.0108\n",
      "Epoch 17/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.8225 - mae: 30.8225\n",
      "Epoch 00017: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 30.8225 - mae: 30.8225 - val_loss: 41.4083 - val_mae: 41.4083 - lr: 0.0108\n",
      "Epoch 18/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.5020 - mae: 30.5020\n",
      "Epoch 00018: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 30.5020 - mae: 30.5020 - val_loss: 55.7009 - val_mae: 55.7009 - lr: 0.0108\n",
      "Epoch 19/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.3184 - mae: 30.3184\n",
      "Epoch 00019: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 30.3184 - mae: 30.3184 - val_loss: 30.2487 - val_mae: 30.2487 - lr: 0.0108\n",
      "Epoch 20/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.0176 - mae: 30.0176\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.008638201653957367.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 377s 599ms/step - loss: 30.0176 - mae: 30.0176 - val_loss: 49.5091 - val_mae: 49.5091 - lr: 0.0108\n",
      "Epoch 21/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 29.8018 - mae: 29.8018\n",
      "Epoch 00021: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 29.8018 - mae: 29.8018 - val_loss: 31.3953 - val_mae: 31.3953 - lr: 0.0086\n",
      "Epoch 22/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 28.9667 - mae: 28.9667\n",
      "Epoch 00022: val_loss did not improve from 28.67182\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 28.9667 - mae: 28.9667 - val_loss: 75.7066 - val_mae: 75.7066 - lr: 0.0086\n",
      "Epoch 23/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 28.8814 - mae: 28.8814\n",
      "Epoch 00023: val_loss improved from 28.67182 to 24.44261, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 383s 609ms/step - loss: 28.8814 - mae: 28.8814 - val_loss: 24.4426 - val_mae: 24.4426 - lr: 0.0086\n",
      "Epoch 24/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 28.4199 - mae: 28.4199\n",
      "Epoch 00024: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 28.4199 - mae: 28.4199 - val_loss: 26.1860 - val_mae: 26.1860 - lr: 0.0086\n",
      "Epoch 25/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 27.4590 - mae: 27.4590\n",
      "Epoch 00025: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 27.4590 - mae: 27.4590 - val_loss: 30.0713 - val_mae: 30.0713 - lr: 0.0086\n",
      "Epoch 26/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 26.5701 - mae: 26.5701\n",
      "Epoch 00026: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 26.5701 - mae: 26.5701 - val_loss: 26.5450 - val_mae: 26.5450 - lr: 0.0086\n",
      "Epoch 27/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 25.0999 - mae: 25.0999\n",
      "Epoch 00027: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 25.0999 - mae: 25.0999 - val_loss: 29.5287 - val_mae: 29.5287 - lr: 0.0086\n",
      "Epoch 28/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 23.5976 - mae: 23.5976\n",
      "Epoch 00028: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 23.5976 - mae: 23.5976 - val_loss: 26.3970 - val_mae: 26.3970 - lr: 0.0086\n",
      "Epoch 29/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 22.7788 - mae: 22.7788\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00691056102514267.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 24.44261\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 22.7788 - mae: 22.7788 - val_loss: 28.5777 - val_mae: 28.5777 - lr: 0.0086\n",
      "Epoch 30/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 21.4746 - mae: 21.4746\n",
      "Epoch 00030: val_loss improved from 24.44261 to 22.80521, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 612ms/step - loss: 21.4746 - mae: 21.4746 - val_loss: 22.8052 - val_mae: 22.8052 - lr: 0.0069\n",
      "Epoch 31/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 20.8655 - mae: 20.8655\n",
      "Epoch 00031: val_loss did not improve from 22.80521\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 20.8655 - mae: 20.8655 - val_loss: 22.8576 - val_mae: 22.8576 - lr: 0.0069\n",
      "Epoch 32/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 20.0020 - mae: 20.0020\n",
      "Epoch 00032: val_loss improved from 22.80521 to 13.41893, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 611ms/step - loss: 20.0020 - mae: 20.0020 - val_loss: 13.4189 - val_mae: 13.4189 - lr: 0.0069\n",
      "Epoch 33/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 19.0301 - mae: 19.0301\n",
      "Epoch 00033: val_loss did not improve from 13.41893\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 19.0301 - mae: 19.0301 - val_loss: 17.3414 - val_mae: 17.3414 - lr: 0.0069\n",
      "Epoch 34/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 18.8242 - mae: 18.8242\n",
      "Epoch 00034: val_loss did not improve from 13.41893\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 18.8242 - mae: 18.8242 - val_loss: 18.9664 - val_mae: 18.9664 - lr: 0.0069\n",
      "Epoch 35/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 18.1077 - mae: 18.1077\n",
      "Epoch 00035: val_loss did not improve from 13.41893\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 18.1077 - mae: 18.1077 - val_loss: 17.3065 - val_mae: 17.3065 - lr: 0.0069\n",
      "Epoch 36/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 17.1396 - mae: 17.1396\n",
      "Epoch 00036: val_loss did not improve from 13.41893\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 17.1396 - mae: 17.1396 - val_loss: 22.3463 - val_mae: 22.3463 - lr: 0.0069\n",
      "Epoch 37/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 16.8573 - mae: 16.8573\n",
      "Epoch 00037: val_loss improved from 13.41893 to 12.68662, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 613ms/step - loss: 16.8573 - mae: 16.8573 - val_loss: 12.6866 - val_mae: 12.6866 - lr: 0.0069\n",
      "Epoch 38/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 15.7196 - mae: 15.7196\n",
      "Epoch 00038: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 15.7196 - mae: 15.7196 - val_loss: 13.9546 - val_mae: 13.9546 - lr: 0.0069\n",
      "Epoch 39/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 15.4863 - mae: 15.4863\n",
      "Epoch 00039: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 15.4863 - mae: 15.4863 - val_loss: 12.8475 - val_mae: 12.8475 - lr: 0.0069\n",
      "Epoch 40/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 14.5235 - mae: 14.5235\n",
      "Epoch 00040: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 14.5235 - mae: 14.5235 - val_loss: 19.7910 - val_mae: 19.7910 - lr: 0.0069\n",
      "Epoch 41/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 14.2133 - mae: 14.2133\n",
      "Epoch 00041: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 14.2133 - mae: 14.2133 - val_loss: 18.4538 - val_mae: 18.4538 - lr: 0.0069\n",
      "Epoch 42/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 13.7253 - mae: 13.7253\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.005528448894619942.\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 13.7253 - mae: 13.7253 - val_loss: 33.1702 - val_mae: 33.1702 - lr: 0.0069\n",
      "Epoch 43/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 12.9777 - mae: 12.9777\n",
      "Epoch 00043: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 12.9777 - mae: 12.9777 - val_loss: 14.0634 - val_mae: 14.0634 - lr: 0.0055\n",
      "Epoch 44/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 12.2325 - mae: 12.2325\n",
      "Epoch 00044: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 12.2325 - mae: 12.2325 - val_loss: 12.9621 - val_mae: 12.9621 - lr: 0.0055\n",
      "Epoch 45/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.7909 - mae: 11.7909\n",
      "Epoch 00045: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 11.7909 - mae: 11.7909 - val_loss: 12.7216 - val_mae: 12.7216 - lr: 0.0055\n",
      "Epoch 46/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.8965 - mae: 11.8965\n",
      "Epoch 00046: val_loss did not improve from 12.68662\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 11.8965 - mae: 11.8965 - val_loss: 14.8287 - val_mae: 14.8287 - lr: 0.0055\n",
      "Epoch 47/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.8864 - mae: 11.8864\n",
      "Epoch 00047: val_loss improved from 12.68662 to 12.33657, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 611ms/step - loss: 11.8864 - mae: 11.8864 - val_loss: 12.3366 - val_mae: 12.3366 - lr: 0.0055\n",
      "Epoch 48/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.4219 - mae: 11.4219\n",
      "Epoch 00048: val_loss improved from 12.33657 to 10.70666, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 613ms/step - loss: 11.4219 - mae: 11.4219 - val_loss: 10.7067 - val_mae: 10.7067 - lr: 0.0055\n",
      "Epoch 49/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.2331 - mae: 11.2331\n",
      "Epoch 00049: val_loss improved from 10.70666 to 10.56786, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 610ms/step - loss: 11.2331 - mae: 11.2331 - val_loss: 10.5679 - val_mae: 10.5679 - lr: 0.0055\n",
      "Epoch 50/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.8659 - mae: 10.8659\n",
      "Epoch 00050: val_loss did not improve from 10.56786\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 10.8659 - mae: 10.8659 - val_loss: 15.8957 - val_mae: 15.8957 - lr: 0.0055\n",
      "Epoch 51/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.0649 - mae: 11.0649\n",
      "Epoch 00051: val_loss did not improve from 10.56786\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 11.0649 - mae: 11.0649 - val_loss: 12.6170 - val_mae: 12.6170 - lr: 0.0055\n",
      "Epoch 52/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.7378 - mae: 10.7378\n",
      "Epoch 00052: val_loss improved from 10.56786 to 8.87031, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 613ms/step - loss: 10.7378 - mae: 10.7378 - val_loss: 8.8703 - val_mae: 8.8703 - lr: 0.0055\n",
      "Epoch 53/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.6546 - mae: 10.6546\n",
      "Epoch 00053: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 10.6546 - mae: 10.6546 - val_loss: 12.9723 - val_mae: 12.9723 - lr: 0.0055\n",
      "Epoch 54/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.5016 - mae: 10.5016\n",
      "Epoch 00054: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 10.5016 - mae: 10.5016 - val_loss: 13.7263 - val_mae: 13.7263 - lr: 0.0055\n",
      "Epoch 55/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.4262 - mae: 10.4262\n",
      "Epoch 00055: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 10.4262 - mae: 10.4262 - val_loss: 11.7447 - val_mae: 11.7447 - lr: 0.0055\n",
      "Epoch 56/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.3748 - mae: 10.3748\n",
      "Epoch 00056: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 10.3748 - mae: 10.3748 - val_loss: 11.1855 - val_mae: 11.1855 - lr: 0.0055\n",
      "Epoch 57/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 10.1686 - mae: 10.1686\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.004422759264707566.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 10.1686 - mae: 10.1686 - val_loss: 9.3555 - val_mae: 9.3555 - lr: 0.0055\n",
      "Epoch 58/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.8699 - mae: 9.8699\n",
      "Epoch 00058: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.8699 - mae: 9.8699 - val_loss: 11.1257 - val_mae: 11.1257 - lr: 0.0044\n",
      "Epoch 59/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.7484 - mae: 9.7484\n",
      "Epoch 00059: val_loss did not improve from 8.87031\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.7484 - mae: 9.7484 - val_loss: 11.0966 - val_mae: 11.0966 - lr: 0.0044\n",
      "Epoch 60/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.7881 - mae: 9.7881\n",
      "Epoch 00060: val_loss improved from 8.87031 to 7.96762, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 610ms/step - loss: 9.7881 - mae: 9.7881 - val_loss: 7.9676 - val_mae: 7.9676 - lr: 0.0044\n",
      "Epoch 61/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.5581 - mae: 9.5581\n",
      "Epoch 00061: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.5581 - mae: 9.5581 - val_loss: 8.6155 - val_mae: 8.6155 - lr: 0.0044\n",
      "Epoch 62/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.5629 - mae: 9.5629\n",
      "Epoch 00062: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 9.5629 - mae: 9.5629 - val_loss: 8.3173 - val_mae: 8.3173 - lr: 0.0044\n",
      "Epoch 63/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.5831 - mae: 9.5831\n",
      "Epoch 00063: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.5831 - mae: 9.5831 - val_loss: 8.4121 - val_mae: 8.4121 - lr: 0.0044\n",
      "Epoch 64/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.6093 - mae: 9.6093\n",
      "Epoch 00064: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.6093 - mae: 9.6093 - val_loss: 24.0946 - val_mae: 24.0946 - lr: 0.0044\n",
      "Epoch 65/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.5517 - mae: 9.5517\n",
      "Epoch 00065: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.5517 - mae: 9.5517 - val_loss: 9.1589 - val_mae: 9.1589 - lr: 0.0044\n",
      "Epoch 66/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.1666 - mae: 9.1666\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0035382073372602465.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 7.96762\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 9.1666 - mae: 9.1666 - val_loss: 8.1425 - val_mae: 8.1425 - lr: 0.0044\n",
      "Epoch 67/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.1581 - mae: 9.1581\n",
      "Epoch 00067: val_loss improved from 7.96762 to 7.94814, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 402s 638ms/step - loss: 9.1581 - mae: 9.1581 - val_loss: 7.9481 - val_mae: 7.9481 - lr: 0.0035\n",
      "Epoch 68/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.0833 - mae: 9.0833\n",
      "Epoch 00068: val_loss improved from 7.94814 to 7.88944, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 422s 670ms/step - loss: 9.0833 - mae: 9.0833 - val_loss: 7.8894 - val_mae: 7.8894 - lr: 0.0035\n",
      "Epoch 69/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.1101 - mae: 9.1101\n",
      "Epoch 00069: val_loss did not improve from 7.88944\n",
      "630/630 [==============================] - 404s 641ms/step - loss: 9.1101 - mae: 9.1101 - val_loss: 8.3348 - val_mae: 8.3348 - lr: 0.0035\n",
      "Epoch 70/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 9.1569 - mae: 9.1569\n",
      "Epoch 00070: val_loss did not improve from 7.88944\n",
      "630/630 [==============================] - 411s 652ms/step - loss: 9.1569 - mae: 9.1569 - val_loss: 8.8739 - val_mae: 8.8739 - lr: 0.0035\n",
      "Epoch 71/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.9572 - mae: 8.9572\n",
      "Epoch 00071: val_loss did not improve from 7.88944\n",
      "630/630 [==============================] - 411s 653ms/step - loss: 8.9572 - mae: 8.9572 - val_loss: 7.9575 - val_mae: 7.9575 - lr: 0.0035\n",
      "Epoch 72/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.9439 - mae: 8.9439\n",
      "Epoch 00072: val_loss did not improve from 7.88944\n",
      "630/630 [==============================] - 399s 634ms/step - loss: 8.9439 - mae: 8.9439 - val_loss: 8.8008 - val_mae: 8.8008 - lr: 0.0035\n",
      "Epoch 73/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.7637 - mae: 8.7637\n",
      "Epoch 00073: val_loss did not improve from 7.88944\n",
      "630/630 [==============================] - 377s 599ms/step - loss: 8.7637 - mae: 8.7637 - val_loss: 8.2033 - val_mae: 8.2033 - lr: 0.0035\n",
      "Epoch 74/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.8654 - mae: 8.8654\n",
      "Epoch 00074: val_loss improved from 7.88944 to 7.53431, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 612ms/step - loss: 8.8654 - mae: 8.8654 - val_loss: 7.5343 - val_mae: 7.5343 - lr: 0.0035\n",
      "Epoch 75/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.7370 - mae: 8.7370\n",
      "Epoch 00075: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.7370 - mae: 8.7370 - val_loss: 7.7590 - val_mae: 7.7590 - lr: 0.0035\n",
      "Epoch 76/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 00076: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.7654 - mae: 8.7654 - val_loss: 8.9793 - val_mae: 8.9793 - lr: 0.0035\n",
      "Epoch 77/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.8465 - mae: 8.8465\n",
      "Epoch 00077: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 8.8465 - mae: 8.8465 - val_loss: 8.0299 - val_mae: 8.0299 - lr: 0.0035\n",
      "Epoch 78/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.7459 - mae: 8.7459\n",
      "Epoch 00078: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.7459 - mae: 8.7459 - val_loss: 8.4974 - val_mae: 8.4974 - lr: 0.0035\n",
      "Epoch 79/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.8173 - mae: 8.8173\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0028305659070611.\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.8173 - mae: 8.8173 - val_loss: 7.9277 - val_mae: 7.9277 - lr: 0.0035\n",
      "Epoch 80/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 00080: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.5880 - mae: 8.5880 - val_loss: 7.6820 - val_mae: 7.6820 - lr: 0.0028\n",
      "Epoch 81/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.5222 - mae: 8.5222\n",
      "Epoch 00081: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.5222 - mae: 8.5222 - val_loss: 7.6199 - val_mae: 7.6199 - lr: 0.0028\n",
      "Epoch 82/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.5208 - mae: 8.5208\n",
      "Epoch 00082: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.5208 - mae: 8.5208 - val_loss: 7.9850 - val_mae: 7.9850 - lr: 0.0028\n",
      "Epoch 83/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.4388 - mae: 8.4388\n",
      "Epoch 00083: val_loss did not improve from 7.53431\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.4388 - mae: 8.4388 - val_loss: 10.0125 - val_mae: 10.0125 - lr: 0.0028\n",
      "Epoch 84/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.4163 - mae: 8.4163\n",
      "Epoch 00084: val_loss improved from 7.53431 to 7.37105, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 384s 610ms/step - loss: 8.4163 - mae: 8.4163 - val_loss: 7.3711 - val_mae: 7.3711 - lr: 0.0028\n",
      "Epoch 85/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.3590 - mae: 8.3590\n",
      "Epoch 00085: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.3590 - mae: 8.3590 - val_loss: 7.9649 - val_mae: 7.9649 - lr: 0.0028\n",
      "Epoch 86/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.4092 - mae: 8.4092\n",
      "Epoch 00086: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.4092 - mae: 8.4092 - val_loss: 10.1809 - val_mae: 10.1809 - lr: 0.0028\n",
      "Epoch 87/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.4032 - mae: 8.4032\n",
      "Epoch 00087: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.4032 - mae: 8.4032 - val_loss: 8.1573 - val_mae: 8.1573 - lr: 0.0028\n",
      "Epoch 88/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.3282 - mae: 8.3282\n",
      "Epoch 00088: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.3282 - mae: 8.3282 - val_loss: 8.4604 - val_mae: 8.4604 - lr: 0.0028\n",
      "Epoch 89/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.3366 - mae: 8.3366\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00226445272564888.\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.3366 - mae: 8.3366 - val_loss: 8.5711 - val_mae: 8.5711 - lr: 0.0028\n",
      "Epoch 90/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.2399 - mae: 8.2399\n",
      "Epoch 00090: val_loss did not improve from 7.37105\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.2399 - mae: 8.2399 - val_loss: 7.4403 - val_mae: 7.4403 - lr: 0.0023\n",
      "Epoch 91/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.2296 - mae: 8.2296\n",
      "Epoch 00091: val_loss improved from 7.37105 to 7.30163, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 613ms/step - loss: 8.2296 - mae: 8.2296 - val_loss: 7.3016 - val_mae: 7.3016 - lr: 0.0023\n",
      "Epoch 92/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.2069 - mae: 8.2069\n",
      "Epoch 00092: val_loss did not improve from 7.30163\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.2069 - mae: 8.2069 - val_loss: 7.3238 - val_mae: 7.3238 - lr: 0.0023\n",
      "Epoch 93/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.0718 - mae: 8.0718\n",
      "Epoch 00093: val_loss did not improve from 7.30163\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.0718 - mae: 8.0718 - val_loss: 7.8319 - val_mae: 7.8319 - lr: 0.0023\n",
      "Epoch 94/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.2398 - mae: 8.2398\n",
      "Epoch 00094: val_loss did not improve from 7.30163\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.2398 - mae: 8.2398 - val_loss: 7.4167 - val_mae: 7.4167 - lr: 0.0023\n",
      "Epoch 95/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.1922 - mae: 8.1922\n",
      "Epoch 00095: val_loss did not improve from 7.30163\n",
      "630/630 [==============================] - 378s 599ms/step - loss: 8.1922 - mae: 8.1922 - val_loss: 7.9074 - val_mae: 7.9074 - lr: 0.0023\n",
      "Epoch 96/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.1286 - mae: 8.1286\n",
      "Epoch 00096: val_loss improved from 7.30163 to 7.26993, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 384s 610ms/step - loss: 8.1286 - mae: 8.1286 - val_loss: 7.2699 - val_mae: 7.2699 - lr: 0.0023\n",
      "Epoch 97/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.0533 - mae: 8.0533\n",
      "Epoch 00097: val_loss did not improve from 7.26993\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.0533 - mae: 8.0533 - val_loss: 7.5264 - val_mae: 7.5264 - lr: 0.0023\n",
      "Epoch 98/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.0097 - mae: 8.0097\n",
      "Epoch 00098: val_loss improved from 7.26993 to 7.09881, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 612ms/step - loss: 8.0097 - mae: 8.0097 - val_loss: 7.0988 - val_mae: 7.0988 - lr: 0.0023\n",
      "Epoch 99/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.0824 - mae: 8.0824\n",
      "Epoch 00099: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.0824 - mae: 8.0824 - val_loss: 7.4958 - val_mae: 7.4958 - lr: 0.0023\n",
      "Epoch 100/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9680 - mae: 7.9680\n",
      "Epoch 00100: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9680 - mae: 7.9680 - val_loss: 7.6331 - val_mae: 7.6331 - lr: 0.0023\n",
      "Epoch 101/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9870 - mae: 7.9870\n",
      "Epoch 00101: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.9870 - mae: 7.9870 - val_loss: 8.1423 - val_mae: 8.1423 - lr: 0.0023\n",
      "Epoch 102/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 8.1065 - mae: 8.1065\n",
      "Epoch 00102: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 8.1065 - mae: 8.1065 - val_loss: 7.2864 - val_mae: 7.2864 - lr: 0.0023\n",
      "Epoch 103/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9927 - mae: 7.9927\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.001811562106013298.\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9927 - mae: 7.9927 - val_loss: 7.4806 - val_mae: 7.4806 - lr: 0.0023\n",
      "Epoch 104/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9823 - mae: 7.9823\n",
      "Epoch 00104: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9823 - mae: 7.9823 - val_loss: 7.1020 - val_mae: 7.1020 - lr: 0.0018\n",
      "Epoch 105/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9195 - mae: 7.9195\n",
      "Epoch 00105: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9195 - mae: 7.9195 - val_loss: 7.5373 - val_mae: 7.5373 - lr: 0.0018\n",
      "Epoch 106/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9029 - mae: 7.9029\n",
      "Epoch 00106: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9029 - mae: 7.9029 - val_loss: 7.4929 - val_mae: 7.4929 - lr: 0.0018\n",
      "Epoch 107/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.8266 - mae: 7.8266\n",
      "Epoch 00107: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.8266 - mae: 7.8266 - val_loss: 7.4888 - val_mae: 7.4888 - lr: 0.0018\n",
      "Epoch 108/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.9713 - mae: 7.9713\n",
      "Epoch 00108: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.9713 - mae: 7.9713 - val_loss: 7.1747 - val_mae: 7.1747 - lr: 0.0018\n",
      "Epoch 109/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7898 - mae: 7.7898\n",
      "Epoch 00109: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.7898 - mae: 7.7898 - val_loss: 7.1744 - val_mae: 7.1744 - lr: 0.0018\n",
      "Epoch 110/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.8428 - mae: 7.8428\n",
      "Epoch 00110: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.8428 - mae: 7.8428 - val_loss: 7.2781 - val_mae: 7.2781 - lr: 0.0018\n",
      "Epoch 111/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7805 - mae: 7.7805\n",
      "Epoch 00111: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.7805 - mae: 7.7805 - val_loss: 7.2284 - val_mae: 7.2284 - lr: 0.0018\n",
      "Epoch 112/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7548 - mae: 7.7548\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0014492496848106384.\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 379s 601ms/step - loss: 7.7548 - mae: 7.7548 - val_loss: 7.1944 - val_mae: 7.1944 - lr: 0.0018\n",
      "Epoch 113/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7107 - mae: 7.7107\n",
      "Epoch 00113: val_loss did not improve from 7.09881\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.7107 - mae: 7.7107 - val_loss: 7.9762 - val_mae: 7.9762 - lr: 0.0014\n",
      "Epoch 114/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6865 - mae: 7.6865\n",
      "Epoch 00114: val_loss improved from 7.09881 to 6.95923, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 610ms/step - loss: 7.6865 - mae: 7.6865 - val_loss: 6.9592 - val_mae: 6.9592 - lr: 0.0014\n",
      "Epoch 115/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6890 - mae: 7.6890\n",
      "Epoch 00115: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.6890 - mae: 7.6890 - val_loss: 7.1028 - val_mae: 7.1028 - lr: 0.0014\n",
      "Epoch 116/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7028 - mae: 7.7028\n",
      "Epoch 00116: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.7028 - mae: 7.7028 - val_loss: 7.4132 - val_mae: 7.4132 - lr: 0.0014\n",
      "Epoch 117/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6775 - mae: 7.6775\n",
      "Epoch 00117: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.6775 - mae: 7.6775 - val_loss: 7.1257 - val_mae: 7.1257 - lr: 0.0014\n",
      "Epoch 118/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6439 - mae: 7.6439\n",
      "Epoch 00118: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.6439 - mae: 7.6439 - val_loss: 6.9885 - val_mae: 6.9885 - lr: 0.0014\n",
      "Epoch 119/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.7256 - mae: 7.7256\n",
      "Epoch 00119: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.7256 - mae: 7.7256 - val_loss: 8.2805 - val_mae: 8.2805 - lr: 0.0014\n",
      "Epoch 120/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6742 - mae: 7.6742\n",
      "Epoch 00120: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.6742 - mae: 7.6742 - val_loss: 7.8824 - val_mae: 7.8824 - lr: 0.0014\n",
      "Epoch 121/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5840 - mae: 7.5840\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0011593997478485107.\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 6.95923\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5840 - mae: 7.5840 - val_loss: 6.9733 - val_mae: 6.9733 - lr: 0.0014\n",
      "Epoch 122/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5274 - mae: 7.5274\n",
      "Epoch 00122: val_loss improved from 6.95923 to 6.89190, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 386s 612ms/step - loss: 7.5274 - mae: 7.5274 - val_loss: 6.8919 - val_mae: 6.8919 - lr: 0.0012\n",
      "Epoch 123/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5230 - mae: 7.5230\n",
      "Epoch 00123: val_loss did not improve from 6.89190\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5230 - mae: 7.5230 - val_loss: 7.0889 - val_mae: 7.0889 - lr: 0.0012\n",
      "Epoch 124/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.6023 - mae: 7.6023\n",
      "Epoch 00124: val_loss did not improve from 6.89190\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.6023 - mae: 7.6023 - val_loss: 7.1476 - val_mae: 7.1476 - lr: 0.0012\n",
      "Epoch 125/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5166 - mae: 7.5166\n",
      "Epoch 00125: val_loss improved from 6.89190 to 6.80783, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 385s 610ms/step - loss: 7.5166 - mae: 7.5166 - val_loss: 6.8078 - val_mae: 6.8078 - lr: 0.0012\n",
      "Epoch 126/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5220 - mae: 7.5220\n",
      "Epoch 00126: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5220 - mae: 7.5220 - val_loss: 7.4157 - val_mae: 7.4157 - lr: 0.0012\n",
      "Epoch 127/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5240 - mae: 7.5240\n",
      "Epoch 00127: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5240 - mae: 7.5240 - val_loss: 7.0410 - val_mae: 7.0410 - lr: 0.0012\n",
      "Epoch 128/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5426 - mae: 7.5426\n",
      "Epoch 00128: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5426 - mae: 7.5426 - val_loss: 6.8165 - val_mae: 6.8165 - lr: 0.0012\n",
      "Epoch 129/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5304 - mae: 7.5304\n",
      "Epoch 00129: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5304 - mae: 7.5304 - val_loss: 6.8795 - val_mae: 6.8795 - lr: 0.0012\n",
      "Epoch 130/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.5377 - mae: 7.5377\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0009275197982788086.\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.5377 - mae: 7.5377 - val_loss: 7.0668 - val_mae: 7.0668 - lr: 0.0012\n",
      "Epoch 131/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.4369 - mae: 7.4369\n",
      "Epoch 00131: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.4369 - mae: 7.4369 - val_loss: 6.9976 - val_mae: 6.9976 - lr: 9.2752e-04\n",
      "Epoch 132/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.3820 - mae: 7.3820\n",
      "Epoch 00132: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.3820 - mae: 7.3820 - val_loss: 6.8364 - val_mae: 6.8364 - lr: 9.2752e-04\n",
      "Epoch 133/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.4074 - mae: 7.4074\n",
      "Epoch 00133: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.4074 - mae: 7.4074 - val_loss: 7.2149 - val_mae: 7.2149 - lr: 9.2752e-04\n",
      "Epoch 134/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.4395 - mae: 7.4395\n",
      "Epoch 00134: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.4395 - mae: 7.4395 - val_loss: 7.2193 - val_mae: 7.2193 - lr: 9.2752e-04\n",
      "Epoch 135/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.3668 - mae: 7.3668\n",
      "Epoch 00135: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 600ms/step - loss: 7.3668 - mae: 7.3668 - val_loss: 6.8481 - val_mae: 6.8481 - lr: 9.2752e-04\n",
      "Epoch 136/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.4367 - mae: 7.4367\n",
      "Epoch 00136: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 378s 601ms/step - loss: 7.4367 - mae: 7.4367 - val_loss: 7.1412 - val_mae: 7.1412 - lr: 9.2752e-04\n",
      "Epoch 137/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.3986 - mae: 7.3986\n",
      "Epoch 00137: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 383s 607ms/step - loss: 7.3986 - mae: 7.3986 - val_loss: 6.9828 - val_mae: 6.9828 - lr: 9.2752e-04\n",
      "Epoch 138/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 7.3475 - mae: 7.3475\n",
      "Epoch 00138: val_loss did not improve from 6.80783\n",
      "630/630 [==============================] - 415s 658ms/step - loss: 7.3475 - mae: 7.3475 - val_loss: 7.2475 - val_mae: 7.2475 - lr: 9.2752e-04\n",
      "Epoch 139/250\n",
      "310/630 [=============>................] - ETA: 3:17 - loss: 7.5343 - mae: 7.5343"
     ]
    }
   ],
   "source": [
    "initalHistory = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=250,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks = callBacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78bcbf71713dd947ce2131f7f6689fb7d7a7279f673cc1a06b2b5cdb722ee962"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('newEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12552.345905,
   "end_time": "2022-04-10T23:21:42.488841",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-10T19:52:30.142936",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
