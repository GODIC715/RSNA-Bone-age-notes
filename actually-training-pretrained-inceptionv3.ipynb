{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b642689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:00.159337Z",
     "iopub.status.busy": "2022-04-02T16:24:00.154508Z",
     "iopub.status.idle": "2022-04-02T16:24:06.765898Z",
     "shell.execute_reply": "2022-04-02T16:24:06.765142Z",
     "shell.execute_reply.started": "2022-04-02T15:36:35.855462Z"
    },
    "papermill": {
     "duration": 6.637682,
     "end_time": "2022-04-02T16:24:06.766061",
     "exception": false,
     "start_time": "2022-04-02T16:24:00.128379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:24:01.796889: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-04-02 16:24:01.797017: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d900e8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:06.807353Z",
     "iopub.status.busy": "2022-04-02T16:24:06.806662Z",
     "iopub.status.idle": "2022-04-02T16:24:12.744368Z",
     "shell.execute_reply": "2022-04-02T16:24:12.743858Z",
     "shell.execute_reply.started": "2022-04-02T15:36:35.873504Z"
    },
    "papermill": {
     "duration": 5.960907,
     "end_time": "2022-04-02T16:24:12.744514",
     "exception": false,
     "start_time": "2022-04-02T16:24:06.783607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: grpc://10.0.0.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:24:06.810241: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-02 16:24:06.812860: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-04-02 16:24:06.812892: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-02 16:24:06.812919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b8f28106fe92): /proc/driver/nvidia/version does not exist\n",
      "2022-04-02 16:24:06.815626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-02 16:24:06.817029: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-02 16:24:06.823088: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-02 16:24:06.849330: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-04-02 16:24:06.849384: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-04-02 16:24:06.871792: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-04-02 16:24:06.871852: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2022-04-02 16:24:06.874073: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee197fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:12.793083Z",
     "iopub.status.busy": "2022-04-02T16:24:12.792414Z",
     "iopub.status.idle": "2022-04-02T16:24:13.288540Z",
     "shell.execute_reply": "2022-04-02T16:24:13.287894Z",
     "shell.execute_reply.started": "2022-04-02T15:36:43.735952Z"
    },
    "papermill": {
     "duration": 0.526488,
     "end_time": "2022-04-02T16:24:13.288699",
     "exception": false,
     "start_time": "2022-04-02T16:24:12.762211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [512, 512]\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('rsnaboneage-tfrecords')\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a6c3acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.330342Z",
     "iopub.status.busy": "2022-04-02T16:24:13.329660Z",
     "iopub.status.idle": "2022-04-02T16:24:13.332482Z",
     "shell.execute_reply": "2022-04-02T16:24:13.331831Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.155633Z"
    },
    "papermill": {
     "duration": 0.025889,
     "end_time": "2022-04-02T16:24:13.332620",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.306731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53283ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.377291Z",
     "iopub.status.busy": "2022-04-02T16:24:13.376254Z",
     "iopub.status.idle": "2022-04-02T16:24:13.378899Z",
     "shell.execute_reply": "2022-04-02T16:24:13.378284Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.164594Z"
    },
    "papermill": {
     "duration": 0.028057,
     "end_time": "2022-04-02T16:24:13.379049",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.350992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'boneage': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'male': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    boneAge = tf.cast(example['boneage'], tf.int32)\n",
    "    male = tf.cast(example['male'], tf.bool)\n",
    "    inputs = {}\n",
    "    inputs['image'] = image\n",
    "    inputs['gender'] = male\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ffd800f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.421834Z",
     "iopub.status.busy": "2022-04-02T16:24:13.420742Z",
     "iopub.status.idle": "2022-04-02T16:24:13.423678Z",
     "shell.execute_reply": "2022-04-02T16:24:13.423065Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.175956Z"
    },
    "papermill": {
     "duration": 0.02698,
     "end_time": "2022-04-02T16:24:13.423814",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.396834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb79ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.464733Z",
     "iopub.status.busy": "2022-04-02T16:24:13.464081Z",
     "iopub.status.idle": "2022-04-02T16:24:13.559183Z",
     "shell.execute_reply": "2022-04-02T16:24:13.559660Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.194801Z"
    },
    "papermill": {
     "duration": 0.118245,
     "end_time": "2022-04-02T16:24:13.559851",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.441606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 16:24:13.469737: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    tf.io.gfile.glob(GCS_PATH + '/bone_age_tfrecords/*.tfrec'),\n",
    "    test_size=0.2, random_state=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e579db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.615414Z",
     "iopub.status.busy": "2022-04-02T16:24:13.614732Z",
     "iopub.status.idle": "2022-04-02T16:24:13.616628Z",
     "shell.execute_reply": "2022-04-02T16:24:13.617100Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.324257Z"
    },
    "papermill": {
     "duration": 0.039235,
     "end_time": "2022-04-02T16:24:13.617262",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.578027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_data_augment(inputs, boneAge):\n",
    "    image = inputs['image']\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, HEIGHT, shear=20.)\n",
    "        else:\n",
    "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    inputs['image'] = image\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00bac37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.668172Z",
     "iopub.status.busy": "2022-04-02T16:24:13.662942Z",
     "iopub.status.idle": "2022-04-02T16:24:13.677210Z",
     "shell.execute_reply": "2022-04-02T16:24:13.677824Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.344991Z"
    },
    "papermill": {
     "duration": 0.042577,
     "end_time": "2022-04-02T16:24:13.678002",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.635425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab91c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.721141Z",
     "iopub.status.busy": "2022-04-02T16:24:13.717552Z",
     "iopub.status.idle": "2022-04-02T16:24:13.723056Z",
     "shell.execute_reply": "2022-04-02T16:24:13.723628Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.371465Z"
    },
    "papermill": {
     "duration": 0.027283,
     "end_time": "2022-04-02T16:24:13.723804",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.696521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)  \n",
    "    dataset = dataset.map(custom_data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ec40f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.764458Z",
     "iopub.status.busy": "2022-04-02T16:24:13.763694Z",
     "iopub.status.idle": "2022-04-02T16:24:13.767499Z",
     "shell.execute_reply": "2022-04-02T16:24:13.768033Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.387303Z"
    },
    "papermill": {
     "duration": 0.025294,
     "end_time": "2022-04-02T16:24:13.768213",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.742919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be3da3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.807298Z",
     "iopub.status.busy": "2022-04-02T16:24:13.806693Z",
     "iopub.status.idle": "2022-04-02T16:24:13.810563Z",
     "shell.execute_reply": "2022-04-02T16:24:13.811132Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.400328Z"
    },
    "papermill": {
     "duration": 0.025026,
     "end_time": "2022-04-02T16:24:13.811303",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.786277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9f694d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.850436Z",
     "iopub.status.busy": "2022-04-02T16:24:13.849804Z",
     "iopub.status.idle": "2022-04-02T16:24:13.854859Z",
     "shell.execute_reply": "2022-04-02T16:24:13.855365Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.410523Z"
    },
    "papermill": {
     "duration": 0.026275,
     "end_time": "2022-04-02T16:24:13.855536",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.829261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10088 training images, 2523 validation images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0f07e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.895475Z",
     "iopub.status.busy": "2022-04-02T16:24:13.894805Z",
     "iopub.status.idle": "2022-04-02T16:24:13.901115Z",
     "shell.execute_reply": "2022-04-02T16:24:13.901634Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.421967Z"
    },
    "papermill": {
     "duration": 0.027852,
     "end_time": "2022-04-02T16:24:13.901815",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.873963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestLr = 0.0107977516232771\n",
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=20)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "\n",
    "optimizer = Adam(learning_rate = bestLr)\n",
    "callBacks = [early, reduceLROnPlat, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4955b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:13.943942Z",
     "iopub.status.busy": "2022-04-02T16:24:13.943222Z",
     "iopub.status.idle": "2022-04-02T16:24:31.268871Z",
     "shell.execute_reply": "2022-04-02T16:24:31.268290Z",
     "shell.execute_reply.started": "2022-04-02T15:36:44.433111Z"
    },
    "papermill": {
     "duration": 17.347328,
     "end_time": "2022-04-02T16:24:31.269013",
     "exception": false,
     "start_time": "2022-04-02T16:24:13.921685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():       \n",
    "    i1 = Input(shape=(512, 512, 3), name='image')\n",
    "    i2 = Input(shape=(1), name='gender')\n",
    "    base = InceptionV3(input_tensor=i1, input_shape=(512, 512, 3), include_top=False, weights = 'imagenet')\n",
    "\n",
    "    feature_img = base.get_layer(name='mixed10').output\n",
    "    feature_img = AveragePooling2D((2, 2))(feature_img)\n",
    "    feature_img = Flatten()(feature_img)\n",
    "    feature_gender = Dense(32, activation='relu')(i2)\n",
    "    feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "    o = Dense(1000, activation='relu')(feature)\n",
    "    o = Dense(1000, activation='relu')(o)\n",
    "    o = Dense(1)(o)\n",
    "    model = Model(inputs=[i1, i2], outputs=o)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de45728b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:31.321243Z",
     "iopub.status.busy": "2022-04-02T16:24:31.320292Z",
     "iopub.status.idle": "2022-04-02T16:24:33.394064Z",
     "shell.execute_reply": "2022-04-02T16:24:33.394566Z",
     "shell.execute_reply.started": "2022-04-02T15:37:02.272133Z"
    },
    "papermill": {
     "duration": 2.103508,
     "end_time": "2022-04-02T16:24:33.394748",
     "exception": false,
     "start_time": "2022-04-02T16:24:31.291240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset()\n",
    "valid_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "766725f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:33.443846Z",
     "iopub.status.busy": "2022-04-02T16:24:33.443197Z",
     "iopub.status.idle": "2022-04-02T16:24:33.446044Z",
     "shell.execute_reply": "2022-04-02T16:24:33.445566Z",
     "shell.execute_reply.started": "2022-04-02T15:37:04.386143Z"
    },
    "papermill": {
     "duration": 0.029311,
     "end_time": "2022-04-02T16:24:33.446190",
     "exception": false,
     "start_time": "2022-04-02T16:24:33.416879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e38aabb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:24:33.498620Z",
     "iopub.status.busy": "2022-04-02T16:24:33.492820Z",
     "iopub.status.idle": "2022-04-02T19:03:35.390438Z",
     "shell.execute_reply": "2022-04-02T19:03:35.391120Z"
    },
    "papermill": {
     "duration": 9541.923066,
     "end_time": "2022-04-02T19:03:35.391365",
     "exception": false,
     "start_time": "2022-04-02T16:24:33.468299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "78/78 [==============================] - 156s 1s/step - loss: 934.8466 - mae: 934.8466 - val_loss: 21350872.0000 - val_mae: 21350872.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 21350872.00000, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 2/250\n",
      "78/78 [==============================] - 54s 699ms/step - loss: 34.9215 - mae: 34.9215 - val_loss: 1356.6046 - val_mae: 1356.6046\n",
      "\n",
      "Epoch 00002: val_loss improved from 21350872.00000 to 1356.60461, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 3/250\n",
      "78/78 [==============================] - 51s 656ms/step - loss: 33.7494 - mae: 33.7494 - val_loss: 37.6423 - val_mae: 37.6423\n",
      "\n",
      "Epoch 00003: val_loss improved from 1356.60461 to 37.64230, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 4/250\n",
      "78/78 [==============================] - 49s 634ms/step - loss: 32.5717 - mae: 32.5717 - val_loss: 31.8595 - val_mae: 31.8595\n",
      "\n",
      "Epoch 00004: val_loss improved from 37.64230 to 31.85949, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 5/250\n",
      "78/78 [==============================] - 50s 639ms/step - loss: 32.4388 - mae: 32.4388 - val_loss: 32.3907 - val_mae: 32.3907\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 31.85949\n",
      "Epoch 6/250\n",
      "78/78 [==============================] - 55s 704ms/step - loss: 32.3620 - mae: 32.3620 - val_loss: 31.4123 - val_mae: 31.4123\n",
      "\n",
      "Epoch 00006: val_loss improved from 31.85949 to 31.41231, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 7/250\n",
      "78/78 [==============================] - 50s 642ms/step - loss: 32.1408 - mae: 32.1408 - val_loss: 38.3920 - val_mae: 38.3920\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 31.41231\n",
      "Epoch 8/250\n",
      "78/78 [==============================] - 56s 716ms/step - loss: 33.1841 - mae: 33.1841 - val_loss: 34.5885 - val_mae: 34.5885\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 31.41231\n",
      "Epoch 9/250\n",
      "78/78 [==============================] - 56s 722ms/step - loss: 31.1518 - mae: 31.1518 - val_loss: 30.6098 - val_mae: 30.6098\n",
      "\n",
      "Epoch 00009: val_loss improved from 31.41231 to 30.60978, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 10/250\n",
      "78/78 [==============================] - 53s 678ms/step - loss: 31.2126 - mae: 31.2126 - val_loss: 32.9433 - val_mae: 32.9433\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 30.60978\n",
      "Epoch 11/250\n",
      "78/78 [==============================] - 54s 697ms/step - loss: 31.1810 - mae: 31.1810 - val_loss: 34.6881 - val_mae: 34.6881\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 30.60978\n",
      "Epoch 12/250\n",
      "78/78 [==============================] - 55s 707ms/step - loss: 31.0971 - mae: 31.0971 - val_loss: 33.0235 - val_mae: 33.0235\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 30.60978\n",
      "Epoch 13/250\n",
      "78/78 [==============================] - 58s 739ms/step - loss: 31.3931 - mae: 31.3931 - val_loss: 34.9256 - val_mae: 34.9256\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 30.60978\n",
      "Epoch 14/250\n",
      "78/78 [==============================] - 57s 733ms/step - loss: 30.5869 - mae: 30.5869 - val_loss: 29.4987 - val_mae: 29.4987\n",
      "\n",
      "Epoch 00014: val_loss improved from 30.60978 to 29.49872, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 15/250\n",
      "78/78 [==============================] - 56s 713ms/step - loss: 31.2762 - mae: 31.2762 - val_loss: 30.3352 - val_mae: 30.3352\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 29.49872\n",
      "Epoch 16/250\n",
      "78/78 [==============================] - 49s 637ms/step - loss: 30.6426 - mae: 30.6426 - val_loss: 38.9022 - val_mae: 38.9022\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 29.49872\n",
      "Epoch 17/250\n",
      "78/78 [==============================] - 55s 701ms/step - loss: 30.7508 - mae: 30.7508 - val_loss: 34.9136 - val_mae: 34.9136\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 29.49872\n",
      "Epoch 18/250\n",
      "78/78 [==============================] - 54s 692ms/step - loss: 30.7006 - mae: 30.7006 - val_loss: 46.3774 - val_mae: 46.3774\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 29.49872\n",
      "Epoch 19/250\n",
      "78/78 [==============================] - 55s 705ms/step - loss: 30.8146 - mae: 30.8146 - val_loss: 38.0736 - val_mae: 38.0736\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.008638201653957367.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 29.49872\n",
      "Epoch 20/250\n",
      "78/78 [==============================] - 55s 708ms/step - loss: 31.4162 - mae: 31.4162 - val_loss: 30.2125 - val_mae: 30.2125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 29.49872\n",
      "Epoch 21/250\n",
      "78/78 [==============================] - 55s 713ms/step - loss: 30.4628 - mae: 30.4628 - val_loss: 32.5869 - val_mae: 32.5869\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 29.49872\n",
      "Epoch 22/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 28.8232 - mae: 28.8232 - val_loss: 48.4058 - val_mae: 48.4058\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 29.49872\n",
      "Epoch 23/250\n",
      "78/78 [==============================] - 56s 720ms/step - loss: 29.1171 - mae: 29.1171 - val_loss: 27.9841 - val_mae: 27.9841\n",
      "\n",
      "Epoch 00023: val_loss improved from 29.49872 to 27.98409, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 24/250\n",
      "78/78 [==============================] - 52s 662ms/step - loss: 27.0408 - mae: 27.0408 - val_loss: 45.0890 - val_mae: 45.0890\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 27.98409\n",
      "Epoch 25/250\n",
      "78/78 [==============================] - 56s 723ms/step - loss: 24.6067 - mae: 24.6067 - val_loss: 72.7977 - val_mae: 72.7977\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 27.98409\n",
      "Epoch 26/250\n",
      "78/78 [==============================] - 57s 737ms/step - loss: 22.6853 - mae: 22.6853 - val_loss: 30.8781 - val_mae: 30.8781\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 27.98409\n",
      "Epoch 27/250\n",
      "78/78 [==============================] - 57s 740ms/step - loss: 21.7862 - mae: 21.7862 - val_loss: 24.0478 - val_mae: 24.0478\n",
      "\n",
      "Epoch 00027: val_loss improved from 27.98409 to 24.04777, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 28/250\n",
      "78/78 [==============================] - 54s 698ms/step - loss: 21.1449 - mae: 21.1449 - val_loss: 23.7227 - val_mae: 23.7227\n",
      "\n",
      "Epoch 00028: val_loss improved from 24.04777 to 23.72275, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 29/250\n",
      "78/78 [==============================] - 55s 708ms/step - loss: 20.1147 - mae: 20.1147 - val_loss: 40.2367 - val_mae: 40.2367\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 23.72275\n",
      "Epoch 30/250\n",
      "78/78 [==============================] - 57s 728ms/step - loss: 18.8093 - mae: 18.8093 - val_loss: 28.0891 - val_mae: 28.0891\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 23.72275\n",
      "Epoch 31/250\n",
      "78/78 [==============================] - 57s 733ms/step - loss: 18.4917 - mae: 18.4917 - val_loss: 22.6212 - val_mae: 22.6212\n",
      "\n",
      "Epoch 00031: val_loss improved from 23.72275 to 22.62121, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 32/250\n",
      "78/78 [==============================] - 55s 704ms/step - loss: 18.0549 - mae: 18.0549 - val_loss: 23.9352 - val_mae: 23.9352\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 22.62121\n",
      "Epoch 33/250\n",
      "78/78 [==============================] - 56s 723ms/step - loss: 16.4627 - mae: 16.4627 - val_loss: 15.6895 - val_mae: 15.6895\n",
      "\n",
      "Epoch 00033: val_loss improved from 22.62121 to 15.68954, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 34/250\n",
      "78/78 [==============================] - 56s 717ms/step - loss: 15.4683 - mae: 15.4683 - val_loss: 41.0737 - val_mae: 41.0737\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 15.68954\n",
      "Epoch 35/250\n",
      "78/78 [==============================] - 56s 729ms/step - loss: 14.7202 - mae: 14.7202 - val_loss: 25.3726 - val_mae: 25.3726\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 15.68954\n",
      "Epoch 36/250\n",
      "78/78 [==============================] - 58s 752ms/step - loss: 14.0845 - mae: 14.0845 - val_loss: 19.4529 - val_mae: 19.4529\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 15.68954\n",
      "Epoch 37/250\n",
      "78/78 [==============================] - 47s 607ms/step - loss: 13.1902 - mae: 13.1902 - val_loss: 14.5305 - val_mae: 14.5305\n",
      "\n",
      "Epoch 00037: val_loss improved from 15.68954 to 14.53054, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 38/250\n",
      "78/78 [==============================] - 50s 645ms/step - loss: 13.1946 - mae: 13.1946 - val_loss: 16.3667 - val_mae: 16.3667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 14.53054\n",
      "Epoch 39/250\n",
      "78/78 [==============================] - 55s 703ms/step - loss: 13.2284 - mae: 13.2284 - val_loss: 14.6359 - val_mae: 14.6359\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 14.53054\n",
      "Epoch 40/250\n",
      "78/78 [==============================] - 55s 710ms/step - loss: 12.6826 - mae: 12.6826 - val_loss: 13.7511 - val_mae: 13.7511\n",
      "\n",
      "Epoch 00040: val_loss improved from 14.53054 to 13.75107, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 41/250\n",
      "78/78 [==============================] - 49s 637ms/step - loss: 12.6212 - mae: 12.6212 - val_loss: 14.6379 - val_mae: 14.6379\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 13.75107\n",
      "Epoch 42/250\n",
      "78/78 [==============================] - 56s 718ms/step - loss: 12.8146 - mae: 12.8146 - val_loss: 22.0456 - val_mae: 22.0456\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 13.75107\n",
      "Epoch 43/250\n",
      "78/78 [==============================] - 55s 711ms/step - loss: 11.9135 - mae: 11.9135 - val_loss: 13.9163 - val_mae: 13.9163\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 13.75107\n",
      "Epoch 44/250\n",
      "78/78 [==============================] - 56s 726ms/step - loss: 11.6598 - mae: 11.6598 - val_loss: 21.5419 - val_mae: 21.5419\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 13.75107\n",
      "Epoch 45/250\n",
      "78/78 [==============================] - 56s 723ms/step - loss: 12.1231 - mae: 12.1231 - val_loss: 22.6218 - val_mae: 22.6218\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00691056102514267.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 13.75107\n",
      "Epoch 46/250\n",
      "78/78 [==============================] - 56s 727ms/step - loss: 11.0530 - mae: 11.0530 - val_loss: 31.4707 - val_mae: 31.4707\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 13.75107\n",
      "Epoch 47/250\n",
      "78/78 [==============================] - 57s 739ms/step - loss: 10.8681 - mae: 10.8681 - val_loss: 12.1458 - val_mae: 12.1458\n",
      "\n",
      "Epoch 00047: val_loss improved from 13.75107 to 12.14575, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 48/250\n",
      "78/78 [==============================] - 52s 673ms/step - loss: 10.7196 - mae: 10.7196 - val_loss: 10.0995 - val_mae: 10.0995\n",
      "\n",
      "Epoch 00048: val_loss improved from 12.14575 to 10.09949, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 49/250\n",
      "78/78 [==============================] - 52s 675ms/step - loss: 10.3602 - mae: 10.3602 - val_loss: 11.0378 - val_mae: 11.0378\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 10.09949\n",
      "Epoch 50/250\n",
      "78/78 [==============================] - 55s 711ms/step - loss: 10.7500 - mae: 10.7500 - val_loss: 13.9114 - val_mae: 13.9114\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 10.09949\n",
      "Epoch 51/250\n",
      "78/78 [==============================] - 57s 739ms/step - loss: 10.7616 - mae: 10.7616 - val_loss: 12.7562 - val_mae: 12.7562\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 10.09949\n",
      "Epoch 52/250\n",
      "78/78 [==============================] - 57s 738ms/step - loss: 10.7720 - mae: 10.7720 - val_loss: 12.1997 - val_mae: 12.1997\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 10.09949\n",
      "Epoch 53/250\n",
      "78/78 [==============================] - 58s 740ms/step - loss: 10.2554 - mae: 10.2554 - val_loss: 10.2475 - val_mae: 10.2475\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 10.09949\n",
      "Epoch 54/250\n",
      "78/78 [==============================] - 58s 747ms/step - loss: 10.7455 - mae: 10.7455 - val_loss: 12.6555 - val_mae: 12.6555\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.005528448894619942.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 10.09949\n",
      "Epoch 55/250\n",
      "78/78 [==============================] - 57s 733ms/step - loss: 10.5216 - mae: 10.5216 - val_loss: 11.0333 - val_mae: 11.0333\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 10.09949\n",
      "Epoch 56/250\n",
      "78/78 [==============================] - 57s 725ms/step - loss: 9.7534 - mae: 9.7534 - val_loss: 12.0042 - val_mae: 12.0042\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 10.09949\n",
      "Epoch 57/250\n",
      "78/78 [==============================] - 55s 700ms/step - loss: 9.6773 - mae: 9.6773 - val_loss: 10.9385 - val_mae: 10.9385\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 10.09949\n",
      "Epoch 58/250\n",
      "78/78 [==============================] - 53s 685ms/step - loss: 9.5353 - mae: 9.5353 - val_loss: 10.4970 - val_mae: 10.4970\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 10.09949\n",
      "Epoch 59/250\n",
      "78/78 [==============================] - 54s 701ms/step - loss: 10.1160 - mae: 10.1160 - val_loss: 10.7415 - val_mae: 10.7415\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 10.09949\n",
      "Epoch 60/250\n",
      "78/78 [==============================] - 56s 717ms/step - loss: 9.6860 - mae: 9.6860 - val_loss: 12.2850 - val_mae: 12.2850\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 10.09949\n",
      "Epoch 61/250\n",
      "78/78 [==============================] - 55s 712ms/step - loss: 9.6216 - mae: 9.6216 - val_loss: 12.8765 - val_mae: 12.8765\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 10.09949\n",
      "Epoch 62/250\n",
      "78/78 [==============================] - 55s 713ms/step - loss: 9.6229 - mae: 9.6229 - val_loss: 11.0406 - val_mae: 11.0406\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 10.09949\n",
      "Epoch 63/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 9.6032 - mae: 9.6032 - val_loss: 10.5112 - val_mae: 10.5112\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.004422759264707566.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 10.09949\n",
      "Epoch 64/250\n",
      "78/78 [==============================] - 57s 737ms/step - loss: 9.2687 - mae: 9.2687 - val_loss: 10.6951 - val_mae: 10.6951\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 10.09949\n",
      "Epoch 65/250\n",
      "78/78 [==============================] - 56s 727ms/step - loss: 9.0951 - mae: 9.0951 - val_loss: 11.2996 - val_mae: 11.2996\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 10.09949\n",
      "Epoch 66/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 9.4508 - mae: 9.4508 - val_loss: 9.0159 - val_mae: 9.0159\n",
      "\n",
      "Epoch 00066: val_loss improved from 10.09949 to 9.01589, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 67/250\n",
      "78/78 [==============================] - 50s 645ms/step - loss: 9.0468 - mae: 9.0468 - val_loss: 13.9799 - val_mae: 13.9799\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 9.01589\n",
      "Epoch 68/250\n",
      "78/78 [==============================] - 56s 723ms/step - loss: 9.0559 - mae: 9.0559 - val_loss: 10.8857 - val_mae: 10.8857\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 9.01589\n",
      "Epoch 69/250\n",
      "78/78 [==============================] - 57s 728ms/step - loss: 8.9658 - mae: 8.9658 - val_loss: 10.0194 - val_mae: 10.0194\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 9.01589\n",
      "Epoch 70/250\n",
      "78/78 [==============================] - 57s 734ms/step - loss: 8.9963 - mae: 8.9963 - val_loss: 11.1950 - val_mae: 11.1950\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 9.01589\n",
      "Epoch 71/250\n",
      "78/78 [==============================] - 57s 731ms/step - loss: 9.1462 - mae: 9.1462 - val_loss: 15.9919 - val_mae: 15.9919\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 9.01589\n",
      "Epoch 72/250\n",
      "78/78 [==============================] - 57s 735ms/step - loss: 8.8975 - mae: 8.8975 - val_loss: 11.3064 - val_mae: 11.3064\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0035382073372602465.\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 9.01589\n",
      "Epoch 73/250\n",
      "78/78 [==============================] - 58s 743ms/step - loss: 8.7804 - mae: 8.7804 - val_loss: 8.8346 - val_mae: 8.8346\n",
      "\n",
      "Epoch 00073: val_loss improved from 9.01589 to 8.83457, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 74/250\n",
      "78/78 [==============================] - 54s 697ms/step - loss: 8.9446 - mae: 8.9446 - val_loss: 8.3954 - val_mae: 8.3954\n",
      "\n",
      "Epoch 00074: val_loss improved from 8.83457 to 8.39540, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 75/250\n",
      "78/78 [==============================] - 56s 717ms/step - loss: 8.6602 - mae: 8.6602 - val_loss: 8.9135 - val_mae: 8.9135\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 8.39540\n",
      "Epoch 76/250\n",
      "78/78 [==============================] - 58s 745ms/step - loss: 8.6183 - mae: 8.6183 - val_loss: 9.9825 - val_mae: 9.9825\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 8.39540\n",
      "Epoch 77/250\n",
      "78/78 [==============================] - 50s 643ms/step - loss: 8.7202 - mae: 8.7202 - val_loss: 9.1068 - val_mae: 9.1068\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 8.39540\n",
      "Epoch 78/250\n",
      "78/78 [==============================] - 56s 715ms/step - loss: 8.5004 - mae: 8.5004 - val_loss: 8.8592 - val_mae: 8.8592\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 8.39540\n",
      "Epoch 79/250\n",
      "78/78 [==============================] - 55s 704ms/step - loss: 8.5491 - mae: 8.5491 - val_loss: 10.4068 - val_mae: 10.4068\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 8.39540\n",
      "Epoch 80/250\n",
      "78/78 [==============================] - 54s 696ms/step - loss: 8.4924 - mae: 8.4924 - val_loss: 8.8829 - val_mae: 8.8829\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 8.39540\n",
      "Epoch 81/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 8.3656 - mae: 8.3656 - val_loss: 9.1686 - val_mae: 9.1686\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0028305659070611.\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 8.39540\n",
      "Epoch 82/250\n",
      "78/78 [==============================] - 57s 729ms/step - loss: 8.5458 - mae: 8.5458 - val_loss: 10.0275 - val_mae: 10.0275\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 8.39540\n",
      "Epoch 83/250\n",
      "78/78 [==============================] - 55s 703ms/step - loss: 8.3886 - mae: 8.3886 - val_loss: 8.7090 - val_mae: 8.7090\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 8.39540\n",
      "Epoch 84/250\n",
      "78/78 [==============================] - 55s 711ms/step - loss: 8.7726 - mae: 8.7726 - val_loss: 8.4588 - val_mae: 8.4588\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 8.39540\n",
      "Epoch 85/250\n",
      "78/78 [==============================] - 56s 718ms/step - loss: 8.4166 - mae: 8.4166 - val_loss: 10.0573 - val_mae: 10.0573\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 8.39540\n",
      "Epoch 86/250\n",
      "78/78 [==============================] - 56s 714ms/step - loss: 8.2442 - mae: 8.2442 - val_loss: 9.2451 - val_mae: 9.2451\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 8.39540\n",
      "Epoch 87/250\n",
      "78/78 [==============================] - 56s 725ms/step - loss: 8.1487 - mae: 8.1487 - val_loss: 8.9475 - val_mae: 8.9475\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 8.39540\n",
      "Epoch 88/250\n",
      "78/78 [==============================] - 57s 733ms/step - loss: 8.2792 - mae: 8.2792 - val_loss: 8.1683 - val_mae: 8.1683\n",
      "\n",
      "Epoch 00088: val_loss improved from 8.39540 to 8.16835, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 89/250\n",
      "78/78 [==============================] - 51s 650ms/step - loss: 8.2493 - mae: 8.2493 - val_loss: 8.2332 - val_mae: 8.2332\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 8.16835\n",
      "Epoch 90/250\n",
      "78/78 [==============================] - 56s 720ms/step - loss: 8.0260 - mae: 8.0260 - val_loss: 9.4895 - val_mae: 9.4895\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 8.16835\n",
      "Epoch 91/250\n",
      "78/78 [==============================] - 58s 736ms/step - loss: 8.1470 - mae: 8.1470 - val_loss: 10.3890 - val_mae: 10.3890\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 8.16835\n",
      "Epoch 92/250\n",
      "78/78 [==============================] - 58s 743ms/step - loss: 8.2966 - mae: 8.2966 - val_loss: 20.5091 - val_mae: 20.5091\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 8.16835\n",
      "Epoch 93/250\n",
      "78/78 [==============================] - 57s 730ms/step - loss: 8.3267 - mae: 8.3267 - val_loss: 10.4495 - val_mae: 10.4495\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00226445272564888.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 8.16835\n",
      "Epoch 94/250\n",
      "78/78 [==============================] - 58s 746ms/step - loss: 8.1297 - mae: 8.1297 - val_loss: 7.8095 - val_mae: 7.8095\n",
      "\n",
      "Epoch 00094: val_loss improved from 8.16835 to 7.80949, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 95/250\n",
      "78/78 [==============================] - 58s 742ms/step - loss: 7.7677 - mae: 7.7677 - val_loss: 8.4990 - val_mae: 8.4990\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 7.80949\n",
      "Epoch 96/250\n",
      "78/78 [==============================] - 58s 754ms/step - loss: 7.8422 - mae: 7.8422 - val_loss: 8.1071 - val_mae: 8.1071\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 7.80949\n",
      "Epoch 97/250\n",
      "78/78 [==============================] - 51s 655ms/step - loss: 7.9911 - mae: 7.9911 - val_loss: 9.2857 - val_mae: 9.2857\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 7.80949\n",
      "Epoch 98/250\n",
      "78/78 [==============================] - 53s 679ms/step - loss: 7.9330 - mae: 7.9330 - val_loss: 9.9935 - val_mae: 9.9935\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 7.80949\n",
      "Epoch 99/250\n",
      "78/78 [==============================] - 56s 718ms/step - loss: 7.7977 - mae: 7.7977 - val_loss: 9.1030 - val_mae: 9.1030\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 7.80949\n",
      "Epoch 100/250\n",
      "78/78 [==============================] - 55s 706ms/step - loss: 7.8009 - mae: 7.8009 - val_loss: 7.8675 - val_mae: 7.8675\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 7.80949\n",
      "Epoch 101/250\n",
      "78/78 [==============================] - 55s 704ms/step - loss: 7.8757 - mae: 7.8757 - val_loss: 8.1735 - val_mae: 8.1735\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 7.80949\n",
      "Epoch 102/250\n",
      "78/78 [==============================] - 55s 704ms/step - loss: 7.8848 - mae: 7.8848 - val_loss: 8.5673 - val_mae: 8.5673\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.001811562106013298.\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 7.80949\n",
      "Epoch 103/250\n",
      "78/78 [==============================] - 56s 721ms/step - loss: 7.9169 - mae: 7.9169 - val_loss: 8.7891 - val_mae: 8.7891\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 7.80949\n",
      "Epoch 104/250\n",
      "78/78 [==============================] - 57s 727ms/step - loss: 7.6293 - mae: 7.6293 - val_loss: 7.7646 - val_mae: 7.7646\n",
      "\n",
      "Epoch 00104: val_loss improved from 7.80949 to 7.76463, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 105/250\n",
      "78/78 [==============================] - 50s 638ms/step - loss: 7.8308 - mae: 7.8308 - val_loss: 8.8147 - val_mae: 8.8147\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 7.76463\n",
      "Epoch 106/250\n",
      "78/78 [==============================] - 57s 726ms/step - loss: 7.6269 - mae: 7.6269 - val_loss: 8.1172 - val_mae: 8.1172\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 7.76463\n",
      "Epoch 107/250\n",
      "78/78 [==============================] - 56s 721ms/step - loss: 7.7084 - mae: 7.7084 - val_loss: 8.0003 - val_mae: 8.0003\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 7.76463\n",
      "Epoch 108/250\n",
      "78/78 [==============================] - 57s 733ms/step - loss: 7.8044 - mae: 7.8044 - val_loss: 8.3318 - val_mae: 8.3318\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 7.76463\n",
      "Epoch 109/250\n",
      "78/78 [==============================] - 56s 716ms/step - loss: 7.6432 - mae: 7.6432 - val_loss: 8.8148 - val_mae: 8.8148\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 7.76463\n",
      "Epoch 110/250\n",
      "78/78 [==============================] - 57s 731ms/step - loss: 7.5573 - mae: 7.5573 - val_loss: 7.9253 - val_mae: 7.9253\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 7.76463\n",
      "Epoch 111/250\n",
      "78/78 [==============================] - 57s 735ms/step - loss: 7.5920 - mae: 7.5920 - val_loss: 8.2313 - val_mae: 8.2313\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0014492496848106384.\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 7.76463\n",
      "Epoch 112/250\n",
      "78/78 [==============================] - 57s 734ms/step - loss: 7.5045 - mae: 7.5045 - val_loss: 8.1962 - val_mae: 8.1962\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 7.76463\n",
      "Epoch 113/250\n",
      "78/78 [==============================] - 59s 753ms/step - loss: 7.6768 - mae: 7.6768 - val_loss: 7.8581 - val_mae: 7.8581\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 7.76463\n",
      "Epoch 114/250\n",
      "78/78 [==============================] - 55s 716ms/step - loss: 7.6487 - mae: 7.6487 - val_loss: 7.9491 - val_mae: 7.9491\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 7.76463\n",
      "Epoch 115/250\n",
      "78/78 [==============================] - 58s 744ms/step - loss: 7.4496 - mae: 7.4496 - val_loss: 8.2918 - val_mae: 8.2918\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 7.76463\n",
      "Epoch 116/250\n",
      "78/78 [==============================] - 58s 743ms/step - loss: 7.5185 - mae: 7.5185 - val_loss: 7.7577 - val_mae: 7.7577\n",
      "\n",
      "Epoch 00116: val_loss improved from 7.76463 to 7.75770, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 117/250\n",
      "78/78 [==============================] - 45s 574ms/step - loss: 7.4692 - mae: 7.4692 - val_loss: 8.1006 - val_mae: 8.1006\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 7.75770\n",
      "Epoch 118/250\n",
      "78/78 [==============================] - 55s 703ms/step - loss: 7.4824 - mae: 7.4824 - val_loss: 8.6539 - val_mae: 8.6539\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 7.75770\n",
      "Epoch 119/250\n",
      "78/78 [==============================] - 54s 699ms/step - loss: 7.5429 - mae: 7.5429 - val_loss: 8.2382 - val_mae: 8.2382\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 7.75770\n",
      "Epoch 120/250\n",
      "78/78 [==============================] - 55s 706ms/step - loss: 7.6474 - mae: 7.6474 - val_loss: 8.1488 - val_mae: 8.1488\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 7.75770\n",
      "Epoch 121/250\n",
      "78/78 [==============================] - 55s 710ms/step - loss: 7.4445 - mae: 7.4445 - val_loss: 9.5345 - val_mae: 9.5345\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0011593997478485107.\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 7.75770\n",
      "Epoch 122/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 7.4220 - mae: 7.4220 - val_loss: 8.5042 - val_mae: 8.5042\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 7.75770\n",
      "Epoch 123/250\n",
      "78/78 [==============================] - 55s 714ms/step - loss: 7.4613 - mae: 7.4613 - val_loss: 7.6418 - val_mae: 7.6418\n",
      "\n",
      "Epoch 00123: val_loss improved from 7.75770 to 7.64178, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 124/250\n",
      "78/78 [==============================] - 50s 641ms/step - loss: 7.3545 - mae: 7.3545 - val_loss: 7.9606 - val_mae: 7.9606\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 7.64178\n",
      "Epoch 125/250\n",
      "78/78 [==============================] - 57s 730ms/step - loss: 7.4712 - mae: 7.4712 - val_loss: 7.3727 - val_mae: 7.3727\n",
      "\n",
      "Epoch 00125: val_loss improved from 7.64178 to 7.37266, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 126/250\n",
      "78/78 [==============================] - 51s 656ms/step - loss: 7.4965 - mae: 7.4965 - val_loss: 8.2036 - val_mae: 8.2036\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 7.37266\n",
      "Epoch 127/250\n",
      "78/78 [==============================] - 56s 728ms/step - loss: 7.5635 - mae: 7.5635 - val_loss: 8.2199 - val_mae: 8.2199\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 7.37266\n",
      "Epoch 128/250\n",
      "78/78 [==============================] - 58s 741ms/step - loss: 7.4328 - mae: 7.4328 - val_loss: 8.1761 - val_mae: 8.1761\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 7.37266\n",
      "Epoch 129/250\n",
      "78/78 [==============================] - 57s 739ms/step - loss: 7.4762 - mae: 7.4762 - val_loss: 7.4076 - val_mae: 7.4076\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 7.37266\n",
      "Epoch 130/250\n",
      "78/78 [==============================] - 59s 756ms/step - loss: 7.4576 - mae: 7.4576 - val_loss: 8.3009 - val_mae: 8.3009\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0009275197982788086.\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 7.37266\n",
      "Epoch 131/250\n",
      "78/78 [==============================] - 58s 748ms/step - loss: 7.3164 - mae: 7.3164 - val_loss: 7.3215 - val_mae: 7.3215\n",
      "\n",
      "Epoch 00131: val_loss improved from 7.37266 to 7.32149, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 132/250\n",
      "78/78 [==============================] - 55s 712ms/step - loss: 7.1567 - mae: 7.1567 - val_loss: 7.7502 - val_mae: 7.7502\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 7.32149\n",
      "Epoch 133/250\n",
      "78/78 [==============================] - 56s 719ms/step - loss: 7.0959 - mae: 7.0959 - val_loss: 7.9689 - val_mae: 7.9689\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 7.32149\n",
      "Epoch 134/250\n",
      "78/78 [==============================] - 58s 748ms/step - loss: 7.2561 - mae: 7.2561 - val_loss: 7.6634 - val_mae: 7.6634\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 7.32149\n",
      "Epoch 135/250\n",
      "78/78 [==============================] - 58s 740ms/step - loss: 7.3136 - mae: 7.3136 - val_loss: 7.6568 - val_mae: 7.6568\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 7.32149\n",
      "Epoch 136/250\n",
      "78/78 [==============================] - 58s 750ms/step - loss: 7.3108 - mae: 7.3108 - val_loss: 7.4025 - val_mae: 7.4025\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 7.32149\n",
      "Epoch 137/250\n",
      "78/78 [==============================] - 58s 746ms/step - loss: 7.0836 - mae: 7.0836 - val_loss: 7.2612 - val_mae: 7.2612\n",
      "\n",
      "Epoch 00137: val_loss improved from 7.32149 to 7.26123, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 138/250\n",
      "78/78 [==============================] - 56s 721ms/step - loss: 7.1295 - mae: 7.1295 - val_loss: 8.1648 - val_mae: 8.1648\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 7.26123\n",
      "Epoch 139/250\n",
      "78/78 [==============================] - 58s 740ms/step - loss: 7.0459 - mae: 7.0459 - val_loss: 7.7952 - val_mae: 7.7952\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 7.26123\n",
      "Epoch 140/250\n",
      "78/78 [==============================] - 57s 732ms/step - loss: 7.1482 - mae: 7.1482 - val_loss: 7.6479 - val_mae: 7.6479\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 7.26123\n",
      "Epoch 141/250\n",
      "78/78 [==============================] - 49s 630ms/step - loss: 7.1659 - mae: 7.1659 - val_loss: 7.3341 - val_mae: 7.3341\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 7.26123\n",
      "Epoch 142/250\n",
      "78/78 [==============================] - 54s 700ms/step - loss: 7.2100 - mae: 7.2100 - val_loss: 7.8093 - val_mae: 7.8093\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0007420158479362727.\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 7.26123\n",
      "Epoch 143/250\n",
      "78/78 [==============================] - 55s 707ms/step - loss: 6.9843 - mae: 6.9843 - val_loss: 7.6012 - val_mae: 7.6012\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 7.26123\n",
      "Epoch 144/250\n",
      "78/78 [==============================] - 55s 707ms/step - loss: 6.9308 - mae: 6.9308 - val_loss: 7.5592 - val_mae: 7.5592\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 7.26123\n",
      "Epoch 145/250\n",
      "78/78 [==============================] - 55s 712ms/step - loss: 6.9766 - mae: 6.9766 - val_loss: 7.8820 - val_mae: 7.8820\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 7.26123\n",
      "Epoch 146/250\n",
      "78/78 [==============================] - 55s 708ms/step - loss: 7.0355 - mae: 7.0355 - val_loss: 7.3174 - val_mae: 7.3174\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 7.26123\n",
      "Epoch 147/250\n",
      "78/78 [==============================] - 56s 728ms/step - loss: 7.0320 - mae: 7.0320 - val_loss: 7.1597 - val_mae: 7.1597\n",
      "\n",
      "Epoch 00147: val_loss improved from 7.26123 to 7.15973, saving model to bone_age_weights.best.hdf5\n",
      "Epoch 148/250\n",
      "78/78 [==============================] - 51s 660ms/step - loss: 7.0458 - mae: 7.0458 - val_loss: 8.7917 - val_mae: 8.7917\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 7.15973\n",
      "Epoch 149/250\n",
      "78/78 [==============================] - 57s 742ms/step - loss: 7.0223 - mae: 7.0223 - val_loss: 7.4916 - val_mae: 7.4916\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 7.15973\n",
      "Epoch 150/250\n",
      "78/78 [==============================] - 57s 741ms/step - loss: 6.8425 - mae: 6.8425 - val_loss: 8.2028 - val_mae: 8.2028\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 7.15973\n",
      "Epoch 151/250\n",
      "78/78 [==============================] - 56s 725ms/step - loss: 6.9908 - mae: 6.9908 - val_loss: 7.2500 - val_mae: 7.2500\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 7.15973\n",
      "Epoch 152/250\n",
      "78/78 [==============================] - 57s 729ms/step - loss: 6.9196 - mae: 6.9196 - val_loss: 7.8495 - val_mae: 7.8495\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0005936126690357924.\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 7.15973\n",
      "Epoch 153/250\n",
      "78/78 [==============================] - 57s 734ms/step - loss: 6.8884 - mae: 6.8884 - val_loss: 7.5543 - val_mae: 7.5543\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 7.15973\n",
      "Epoch 154/250\n",
      "78/78 [==============================] - 58s 746ms/step - loss: 6.9263 - mae: 6.9263 - val_loss: 7.3834 - val_mae: 7.3834\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 7.15973\n",
      "Epoch 155/250\n",
      "78/78 [==============================] - 57s 734ms/step - loss: 6.8747 - mae: 6.8747 - val_loss: 7.3059 - val_mae: 7.3059\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 7.15973\n",
      "Epoch 156/250\n",
      "78/78 [==============================] - 58s 741ms/step - loss: 6.8513 - mae: 6.8513 - val_loss: 7.9818 - val_mae: 7.9818\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 7.15973\n",
      "Epoch 157/250\n",
      "78/78 [==============================] - 58s 750ms/step - loss: 6.7597 - mae: 6.7597 - val_loss: 7.1664 - val_mae: 7.1664\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 7.15973\n",
      "Epoch 158/250\n",
      "78/78 [==============================] - 58s 751ms/step - loss: 6.9042 - mae: 6.9042 - val_loss: 7.5754 - val_mae: 7.5754\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 7.15973\n",
      "Epoch 159/250\n",
      "78/78 [==============================] - 58s 750ms/step - loss: 6.8740 - mae: 6.8740 - val_loss: 7.5286 - val_mae: 7.5286\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 7.15973\n",
      "Epoch 160/250\n",
      "78/78 [==============================] - 58s 744ms/step - loss: 6.9533 - mae: 6.9533 - val_loss: 7.3698 - val_mae: 7.3698\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 7.15973\n",
      "Epoch 161/250\n",
      "78/78 [==============================] - 59s 760ms/step - loss: 6.8404 - mae: 6.8404 - val_loss: 7.2567 - val_mae: 7.2567\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0004748901352286339.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 7.15973\n",
      "Epoch 162/250\n",
      "78/78 [==============================] - 58s 746ms/step - loss: 6.8419 - mae: 6.8419 - val_loss: 7.2446 - val_mae: 7.2446\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 7.15973\n",
      "Epoch 163/250\n",
      "78/78 [==============================] - 58s 754ms/step - loss: 6.7621 - mae: 6.7621 - val_loss: 7.3036 - val_mae: 7.3036\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 7.15973\n",
      "Epoch 164/250\n",
      "78/78 [==============================] - 54s 696ms/step - loss: 6.7423 - mae: 6.7423 - val_loss: 7.7863 - val_mae: 7.7863\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 7.15973\n",
      "Epoch 165/250\n",
      "78/78 [==============================] - 55s 708ms/step - loss: 6.7326 - mae: 6.7326 - val_loss: 7.9086 - val_mae: 7.9086\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 7.15973\n",
      "Epoch 166/250\n",
      "78/78 [==============================] - 55s 701ms/step - loss: 6.7452 - mae: 6.7452 - val_loss: 7.5497 - val_mae: 7.5497\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 7.15973\n",
      "Epoch 167/250\n",
      "78/78 [==============================] - 55s 710ms/step - loss: 6.8005 - mae: 6.8005 - val_loss: 7.2664 - val_mae: 7.2664\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 7.15973\n"
     ]
    }
   ],
   "source": [
    "initalHistory = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=250,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks = callBacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a81548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T19:03:43.891322Z",
     "iopub.status.busy": "2022-04-02T19:03:43.878702Z",
     "iopub.status.idle": "2022-04-02T19:04:51.413209Z",
     "shell.execute_reply": "2022-04-02T19:04:51.412660Z"
    },
    "papermill": {
     "duration": 71.831055,
     "end_time": "2022-04-02T19:04:51.413626",
     "exception": true,
     "start_time": "2022-04-02T19:03:39.582571",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 19:04:04.526349: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-04-02 19:04:47.226676: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 267432, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1648926287.222752921\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 267432, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "File system scheme '[local]' not implemented (file: 'saved_model/variables/variables_temp/part-00000-of-00001')\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3481366099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2002\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 157\u001b[0;31m                           signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1048\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure save operations have completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m       raise FileNotFoundError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36masync_wait\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2328\u001b[0m   \u001b[0man\u001b[0m \u001b[0merror\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m   \"\"\"\n\u001b[0;32m-> 2330\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_executors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36msync_executors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextSyncExecutors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Context is not initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: 'saved_model/variables/variables_temp/part-00000-of-00001')\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors."
     ]
    }
   ],
   "source": [
    "model.save('saved_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9666.400541,
   "end_time": "2022-04-02T19:04:58.379484",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-02T16:23:51.978943",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
