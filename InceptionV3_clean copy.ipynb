{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "from keras import Input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from flow_dataframe import flow_from_dataframe\n",
    "\n",
    "# hyperparameters\n",
    "NUM_EPOCHS = 149\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE_TRAIN = 16\n",
    "BATCH_SIZE_VAL = 16\n",
    "\n",
    "\n",
    "# default size of InceptionResNetV2\n",
    "IMG_SIZE = (299, 299)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
    "\n",
    "core_idg = ImageDataGenerator(zoom_range=0.2,\n",
    "                              fill_mode='nearest',\n",
    "                              featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                              samplewise_center=False,  # set each sample mean to 0\n",
    "                              featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                              samplewise_std_normalization=False,  # divide each input by its std\n",
    "                              zca_whitening=False,  # apply ZCA whitening\n",
    "                              rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                              width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                              height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                              horizontal_flip=True,  # randomly flip images\n",
    "                              vertical_flip=False)\n",
    "\n",
    "val_idg = ImageDataGenerator(width_shift_range=0.25, height_shift_range=0.25, horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Generators\n",
    "### Reading RSNA Boneage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12611 images found of 12611 total\n",
      "train 10088 validation 2523\n",
      "flow_from_dataframe() -->\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 10088 images\n",
      "flow_from_dataframe() <--\n",
      "flow_from_dataframe() -->\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 2523 images\n",
      "flow_from_dataframe() <--\n"
     ]
    }
   ],
   "source": [
    "class_str_col = 'boneage'\n",
    "gender_str_col = 'male'\n",
    "\n",
    "base_bone_dir = os.path.join('rsna-bone-age')\n",
    "boneage_df = pd.read_csv(os.path.join(base_bone_dir, 'boneage-training-dataset.csv'))\n",
    "boneage_df['path'] = boneage_df['id'].map(lambda x: os.path.join(base_bone_dir,\n",
    "                                                         'boneage-training-dataset', \n",
    "                                                         'boneage-training-dataset', \n",
    "                                                         '{}.png'.format(x)))\n",
    "\n",
    "boneage_df['exists'] = boneage_df['path'].map(os.path.exists)\n",
    "print(boneage_df['exists'].sum(), 'images found of', boneage_df.shape[0], 'total')\n",
    "\n",
    "boneage_df[gender_str_col] = boneage_df[gender_str_col].map(lambda x: np.array([1]) if x else np.array([0])) # map boolean values to 1 and 0\n",
    "\n",
    "train_df_boneage, valid_df_boneage = train_test_split(boneage_df, test_size=0.2,\n",
    "                                                      random_state=2018)  # ,stratify=boneage_df['boneage_category'])\n",
    "print('train', train_df_boneage.shape[0], 'validation', valid_df_boneage.shape[0])\n",
    "\n",
    "train_gen_boneage = flow_from_dataframe(core_idg, train_df_boneage, path_col='path', y_col=class_str_col,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='rgb', batch_size=BATCH_SIZE_TRAIN)\n",
    "\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_gen_boneage = flow_from_dataframe(core_idg, valid_df_boneage, path_col='path', y_col=class_str_col,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='rgb',\n",
    "                                        batch_size=BATCH_SIZE_VAL)  # we can use much larger batches for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = Input(shape=(299, 299, 3), name='input_img')\n",
    "i2 = Input(shape=(1), name='input_gender')\n",
    "base = InceptionV3(input_tensor=i1, input_shape=(299, 299, 3), include_top=False, weights=None)\n",
    "\n",
    "feature_img = base.get_layer(name='mixed10').output\n",
    "feature_img = AveragePooling2D((2, 2))(feature_img)\n",
    "feature_img = Flatten()(feature_img)\n",
    "feature_gender = Dense(32, activation='relu')(i2)\n",
    "feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "o = Dense(1000, activation='relu')(feature)\n",
    "o = Dense(1000, activation='relu')(o)\n",
    "o = Dense(1)(o)\n",
    "model = Model(inputs=[i1, i2], outputs=o)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model on Boneage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=15)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=15, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "\n",
    "\n",
    "def combined_generators(image_generator, gender_data, batch_size):\n",
    "    gender_generator = cycle(batch(gender_data, batch_size))\n",
    "    while True:\n",
    "        nextImage = next(image_generator)\n",
    "        nextGender = next(gender_generator)\n",
    "        nextGender=np.asarray(nextGender).astype(int)\n",
    "        assert len(nextImage[0]) == len(nextGender)\n",
    "        yield [nextImage[0], nextGender], nextImage[1]\n",
    "\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "train_gen_wrapper = combined_generators(train_gen_boneage, train_df_boneage[gender_str_col], BATCH_SIZE_TRAIN)\n",
    "val_gen_wrapper = combined_generators(valid_gen_boneage, valid_df_boneage[gender_str_col], BATCH_SIZE_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.8659 - mae: 10.8659\n",
      "Epoch 00001: val_loss improved from inf to 15.61905, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 925s 1s/step - loss: 10.8659 - mae: 10.8659 - val_loss: 15.6190 - val_mae: 15.6190 - lr: 0.0010\n",
      "Epoch 2/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.8079 - mae: 10.8079\n",
      "Epoch 00002: val_loss improved from 15.61905 to 12.28599, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 780s 1s/step - loss: 10.8079 - mae: 10.8079 - val_loss: 12.2860 - val_mae: 12.2860 - lr: 0.0010\n",
      "Epoch 3/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.6807 - mae: 10.6807\n",
      "Epoch 00003: val_loss did not improve from 12.28599\n",
      "631/631 [==============================] - 675s 1s/step - loss: 10.6807 - mae: 10.6807 - val_loss: 12.8580 - val_mae: 12.8580 - lr: 0.0010\n",
      "Epoch 4/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.7562 - mae: 10.7562\n",
      "Epoch 00004: val_loss did not improve from 12.28599\n",
      "631/631 [==============================] - 652s 1s/step - loss: 10.7562 - mae: 10.7562 - val_loss: 13.0487 - val_mae: 13.0487 - lr: 0.0010\n",
      "Epoch 5/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.7677 - mae: 10.7677\n",
      "Epoch 00005: val_loss improved from 12.28599 to 10.90051, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 662s 1s/step - loss: 10.7677 - mae: 10.7677 - val_loss: 10.9005 - val_mae: 10.9005 - lr: 0.0010\n",
      "Epoch 6/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.7161 - mae: 10.7161\n",
      "Epoch 00006: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 768s 1s/step - loss: 10.7161 - mae: 10.7161 - val_loss: 13.3506 - val_mae: 13.3506 - lr: 0.0010\n",
      "Epoch 7/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.7197 - mae: 10.7197\n",
      "Epoch 00007: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 656s 1s/step - loss: 10.7197 - mae: 10.7197 - val_loss: 13.4802 - val_mae: 13.4802 - lr: 0.0010\n",
      "Epoch 8/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.6424 - mae: 10.6424\n",
      "Epoch 00008: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 660s 1s/step - loss: 10.6424 - mae: 10.6424 - val_loss: 15.0039 - val_mae: 15.0039 - lr: 0.0010\n",
      "Epoch 9/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.5352 - mae: 10.5352\n",
      "Epoch 00009: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 655s 1s/step - loss: 10.5352 - mae: 10.5352 - val_loss: 12.1068 - val_mae: 12.1068 - lr: 0.0010\n",
      "Epoch 10/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.6496 - mae: 10.6496\n",
      "Epoch 00010: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 653s 1s/step - loss: 10.6496 - mae: 10.6496 - val_loss: 11.4062 - val_mae: 11.4062 - lr: 0.0010\n",
      "Epoch 11/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.5327 - mae: 10.5327\n",
      "Epoch 00011: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 759s 1s/step - loss: 10.5327 - mae: 10.5327 - val_loss: 11.3391 - val_mae: 11.3391 - lr: 0.0010\n",
      "Epoch 12/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.6303 - mae: 10.6303\n",
      "Epoch 00012: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 689s 1s/step - loss: 10.6303 - mae: 10.6303 - val_loss: 14.1489 - val_mae: 14.1489 - lr: 0.0010\n",
      "Epoch 13/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.5170 - mae: 10.5170\n",
      "Epoch 00013: val_loss did not improve from 10.90051\n",
      "631/631 [==============================] - 656s 1s/step - loss: 10.5170 - mae: 10.5170 - val_loss: 12.1174 - val_mae: 12.1174 - lr: 0.0010\n",
      "Epoch 14/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.4686 - mae: 10.4686\n",
      "Epoch 00014: val_loss improved from 10.90051 to 10.41282, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 651s 1s/step - loss: 10.4686 - mae: 10.4686 - val_loss: 10.4128 - val_mae: 10.4128 - lr: 0.0010\n",
      "Epoch 15/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.6109 - mae: 10.6109\n",
      "Epoch 00015: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 660s 1s/step - loss: 10.6109 - mae: 10.6109 - val_loss: 10.8372 - val_mae: 10.8372 - lr: 0.0010\n",
      "Epoch 16/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.5236 - mae: 10.5236\n",
      "Epoch 00016: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 656s 1s/step - loss: 10.5236 - mae: 10.5236 - val_loss: 11.2748 - val_mae: 11.2748 - lr: 0.0010\n",
      "Epoch 17/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.2516 - mae: 10.2516\n",
      "Epoch 00017: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 720s 1s/step - loss: 10.2516 - mae: 10.2516 - val_loss: 12.8052 - val_mae: 12.8052 - lr: 0.0010\n",
      "Epoch 18/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.3671 - mae: 10.3671\n",
      "Epoch 00018: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 656s 1s/step - loss: 10.3671 - mae: 10.3671 - val_loss: 10.9233 - val_mae: 10.9233 - lr: 0.0010\n",
      "Epoch 19/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.2921 - mae: 10.2921\n",
      "Epoch 00019: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 649s 1s/step - loss: 10.2921 - mae: 10.2921 - val_loss: 11.4117 - val_mae: 11.4117 - lr: 0.0010\n",
      "Epoch 20/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.3422 - mae: 10.3422\n",
      "Epoch 00020: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 656s 1s/step - loss: 10.3422 - mae: 10.3422 - val_loss: 10.6254 - val_mae: 10.6254 - lr: 0.0010\n",
      "Epoch 21/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.3567 - mae: 10.3567\n",
      "Epoch 00021: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 647s 1s/step - loss: 10.3567 - mae: 10.3567 - val_loss: 11.1372 - val_mae: 11.1372 - lr: 0.0010\n",
      "Epoch 22/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.2790 - mae: 10.2790\n",
      "Epoch 00022: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 748s 1s/step - loss: 10.2790 - mae: 10.2790 - val_loss: 11.6261 - val_mae: 11.6261 - lr: 0.0010\n",
      "Epoch 23/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.3457 - mae: 10.3457\n",
      "Epoch 00023: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 663s 1s/step - loss: 10.3457 - mae: 10.3457 - val_loss: 12.8480 - val_mae: 12.8480 - lr: 0.0010\n",
      "Epoch 24/173\n",
      "631/631 [==============================] - ETA: 0s - loss: 10.2709 - mae: 10.2709\n",
      "Epoch 00024: val_loss did not improve from 10.41282\n",
      "631/631 [==============================] - 649s 1s/step - loss: 10.2709 - mae: 10.2709 - val_loss: 12.9694 - val_mae: 12.9694 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen_wrapper, validation_data=val_gen_wrapper,\n",
    "                              epochs=NUM_EPOCHS, steps_per_epoch=len(train_gen_boneage),\n",
    "                              validation_steps=len(valid_gen_boneage),\n",
    "                              callbacks=[early, reduceLROnPlat, checkpoint])\n",
    "\n",
    "model.save('saved_model.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5898fd49d3a85f7f6a1728e6c8cd77fe1356b68e4a2df5dc09cb8f4bba0dc5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
