{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [600, 600]\n",
    "# GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "HEIGHT = IMAGE_SIZE[0]\n",
    "WIDTH = IMAGE_SIZE[1]\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'boneage': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'male': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    boneAge = tf.cast(example['boneage'], tf.int32)\n",
    "    male = tf.cast(example['male'], tf.bool)\n",
    "    inputs = {}\n",
    "    inputs['image'] = image\n",
    "    inputs['gender'] = male\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
    "    # tf.io.gfile.glob(GCS_PATH + '/bone_age_tfrecords/*.tfrec'),\n",
    "    tf.io.gfile.glob('../bone-age-tfrecords/*.tfrec'),\n",
    "    test_size=0.2, random_state=2018\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_augment(inputs, boneAge):\n",
    "    image = inputs['image']\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    # p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    # Shear\n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, HEIGHT, shear=20.)\n",
    "        else:\n",
    "            image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > .75:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .5:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    elif p_rotate > .25:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    # if p_pixel_1 >= .4:\n",
    "    #     image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > .7:\n",
    "        if p_crop > .9:\n",
    "            image = tf.image.central_crop(image, central_fraction=.6)\n",
    "        elif p_crop > .8:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "    elif p_crop > .4:\n",
    "        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    inputs['image'] = image\n",
    "    return inputs, boneAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES)  \n",
    "    dataset = dataset.map(custom_data_augment, num_parallel_calls=AUTOTUNE)  \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset():\n",
    "    dataset = load_dataset(VALID_FILENAMES) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10088 training images, 2523 validation images\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLr = 0.0107977516232771\n",
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=20)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "optimizer = Adam(learning_rate = bestLr, beta_1 = 0.9, beta_2 = 0.999, epsilon = 0.1, amsgrad=True)\n",
    "callBacks = [early, reduceLROnPlat, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():       \n",
    "    i1 = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), name='image')\n",
    "    i2 = Input(shape=(1), name='gender')\n",
    "    base = InceptionV3(input_tensor=i1, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1), include_top=False, weights=None)\n",
    "\n",
    "    feature_img = base.get_layer(name='mixed10').output\n",
    "    feature_img = AveragePooling2D((2, 2))(feature_img)\n",
    "    feature_img = Flatten()(feature_img)\n",
    "    feature_gender = Dense(32, activation='relu')(i2)\n",
    "    feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "    o = Dense(1000, activation='relu')(feature)\n",
    "    o = Dense(1000, activation='relu')(o)\n",
    "    o = Dense(1)(o)\n",
    "    model = Model(inputs=[i1, i2], outputs=o)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_training_dataset()\n",
    "valid_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 38.7952 - mae: 38.7952\n",
      "Epoch 1: val_loss improved from inf to 109.80080, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 455s 668ms/step - loss: 38.7952 - mae: 38.7952 - val_loss: 109.8008 - val_mae: 109.8008 - lr: 0.0108\n",
      "Epoch 2/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 35.3663 - mae: 35.3663\n",
      "Epoch 2: val_loss improved from 109.80080 to 33.45603, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 423s 671ms/step - loss: 35.3663 - mae: 35.3663 - val_loss: 33.4560 - val_mae: 33.4560 - lr: 0.0108\n",
      "Epoch 3/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 34.1297 - mae: 34.1297\n",
      "Epoch 3: val_loss improved from 33.45603 to 31.55171, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 426s 675ms/step - loss: 34.1297 - mae: 34.1297 - val_loss: 31.5517 - val_mae: 31.5517 - lr: 0.0108\n",
      "Epoch 4/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.6589 - mae: 32.6589\n",
      "Epoch 4: val_loss improved from 31.55171 to 29.54981, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 428s 679ms/step - loss: 32.6589 - mae: 32.6589 - val_loss: 29.5498 - val_mae: 29.5498 - lr: 0.0108\n",
      "Epoch 5/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.0732 - mae: 32.0732\n",
      "Epoch 5: val_loss improved from 29.54981 to 29.05000, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 418s 663ms/step - loss: 32.0732 - mae: 32.0732 - val_loss: 29.0500 - val_mae: 29.0500 - lr: 0.0108\n",
      "Epoch 6/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 31.8092 - mae: 31.8092\n",
      "Epoch 6: val_loss did not improve from 29.05000\n",
      "630/630 [==============================] - 413s 655ms/step - loss: 31.8092 - mae: 31.8092 - val_loss: 30.2412 - val_mae: 30.2412 - lr: 0.0108\n",
      "Epoch 7/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 32.0424 - mae: 32.0424\n",
      "Epoch 7: val_loss did not improve from 29.05000\n",
      "630/630 [==============================] - 423s 671ms/step - loss: 32.0424 - mae: 32.0424 - val_loss: 55.4670 - val_mae: 55.4670 - lr: 0.0108\n",
      "Epoch 8/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.8304 - mae: 30.8304\n",
      "Epoch 8: val_loss did not improve from 29.05000\n",
      "630/630 [==============================] - 422s 670ms/step - loss: 30.8304 - mae: 30.8304 - val_loss: 35.5186 - val_mae: 35.5186 - lr: 0.0108\n",
      "Epoch 9/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 30.2648 - mae: 30.2648\n",
      "Epoch 9: val_loss did not improve from 29.05000\n",
      "630/630 [==============================] - 412s 654ms/step - loss: 30.2648 - mae: 30.2648 - val_loss: 60.3868 - val_mae: 60.3868 - lr: 0.0108\n",
      "Epoch 10/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 29.4299 - mae: 29.4299\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.008638201653957367.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 29.05000\n",
      "630/630 [==============================] - 407s 646ms/step - loss: 29.4299 - mae: 29.4299 - val_loss: 82.1665 - val_mae: 82.1665 - lr: 0.0108\n",
      "Epoch 11/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 27.7152 - mae: 27.7152\n",
      "Epoch 11: val_loss improved from 29.05000 to 26.04346, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 406s 645ms/step - loss: 27.7152 - mae: 27.7152 - val_loss: 26.0435 - val_mae: 26.0435 - lr: 0.0086\n",
      "Epoch 12/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 26.6636 - mae: 26.6636\n",
      "Epoch 12: val_loss improved from 26.04346 to 21.98950, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 407s 645ms/step - loss: 26.6636 - mae: 26.6636 - val_loss: 21.9895 - val_mae: 21.9895 - lr: 0.0086\n",
      "Epoch 13/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 25.3343 - mae: 25.3343\n",
      "Epoch 13: val_loss did not improve from 21.98950\n",
      "630/630 [==============================] - 399s 633ms/step - loss: 25.3343 - mae: 25.3343 - val_loss: 27.6357 - val_mae: 27.6357 - lr: 0.0086\n",
      "Epoch 14/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 24.1913 - mae: 24.1913\n",
      "Epoch 14: val_loss did not improve from 21.98950\n",
      "630/630 [==============================] - 403s 640ms/step - loss: 24.1913 - mae: 24.1913 - val_loss: 63.9835 - val_mae: 63.9835 - lr: 0.0086\n",
      "Epoch 15/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 23.4443 - mae: 23.4443\n",
      "Epoch 15: val_loss did not improve from 21.98950\n",
      "630/630 [==============================] - 403s 640ms/step - loss: 23.4443 - mae: 23.4443 - val_loss: 57.4297 - val_mae: 57.4297 - lr: 0.0086\n",
      "Epoch 16/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 22.1799 - mae: 22.1799\n",
      "Epoch 16: val_loss improved from 21.98950 to 15.65332, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 403s 639ms/step - loss: 22.1799 - mae: 22.1799 - val_loss: 15.6533 - val_mae: 15.6533 - lr: 0.0086\n",
      "Epoch 17/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 20.7105 - mae: 20.7105\n",
      "Epoch 17: val_loss improved from 15.65332 to 14.84276, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 401s 636ms/step - loss: 20.7105 - mae: 20.7105 - val_loss: 14.8428 - val_mae: 14.8428 - lr: 0.0086\n",
      "Epoch 18/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 20.2615 - mae: 20.2615\n",
      "Epoch 18: val_loss did not improve from 14.84276\n",
      "630/630 [==============================] - 393s 623ms/step - loss: 20.2615 - mae: 20.2615 - val_loss: 24.7527 - val_mae: 24.7527 - lr: 0.0086\n",
      "Epoch 19/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 19.2302 - mae: 19.2302\n",
      "Epoch 19: val_loss did not improve from 14.84276\n",
      "630/630 [==============================] - 406s 645ms/step - loss: 19.2302 - mae: 19.2302 - val_loss: 24.4286 - val_mae: 24.4286 - lr: 0.0086\n",
      "Epoch 20/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 18.6002 - mae: 18.6002\n",
      "Epoch 20: val_loss did not improve from 14.84276\n",
      "630/630 [==============================] - 422s 670ms/step - loss: 18.6002 - mae: 18.6002 - val_loss: 23.0074 - val_mae: 23.0074 - lr: 0.0086\n",
      "Epoch 21/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 17.5985 - mae: 17.5985\n",
      "Epoch 21: val_loss did not improve from 14.84276\n",
      "630/630 [==============================] - 408s 647ms/step - loss: 17.5985 - mae: 17.5985 - val_loss: 18.8579 - val_mae: 18.8579 - lr: 0.0086\n",
      "Epoch 22/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 16.2530 - mae: 16.2530\n",
      "Epoch 22: val_loss improved from 14.84276 to 14.65566, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 412s 654ms/step - loss: 16.2530 - mae: 16.2530 - val_loss: 14.6557 - val_mae: 14.6557 - lr: 0.0086\n",
      "Epoch 23/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 23: val_loss did not improve from 14.65566\n",
      "630/630 [==============================] - 408s 647ms/step - loss: 15.8985 - mae: 15.8985 - val_loss: 21.7423 - val_mae: 21.7423 - lr: 0.0086\n",
      "Epoch 24/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 15.1909 - mae: 15.1909\n",
      "Epoch 24: val_loss improved from 14.65566 to 12.54540, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 412s 654ms/step - loss: 15.1909 - mae: 15.1909 - val_loss: 12.5454 - val_mae: 12.5454 - lr: 0.0086\n",
      "Epoch 25/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 14.5750 - mae: 14.5750\n",
      "Epoch 25: val_loss did not improve from 12.54540\n",
      "630/630 [==============================] - 406s 644ms/step - loss: 14.5750 - mae: 14.5750 - val_loss: 22.0900 - val_mae: 22.0900 - lr: 0.0086\n",
      "Epoch 26/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 14.3341 - mae: 14.3341\n",
      "Epoch 26: val_loss improved from 12.54540 to 11.53802, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 419s 665ms/step - loss: 14.3341 - mae: 14.3341 - val_loss: 11.5380 - val_mae: 11.5380 - lr: 0.0086\n",
      "Epoch 27/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 13.6266 - mae: 13.6266\n",
      "Epoch 27: val_loss did not improve from 11.53802\n",
      "630/630 [==============================] - 404s 641ms/step - loss: 13.6266 - mae: 13.6266 - val_loss: 11.9501 - val_mae: 11.9501 - lr: 0.0086\n",
      "Epoch 28/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 13.1594 - mae: 13.1594\n",
      "Epoch 28: val_loss did not improve from 11.53802\n",
      "630/630 [==============================] - 405s 643ms/step - loss: 13.1594 - mae: 13.1594 - val_loss: 17.3688 - val_mae: 17.3688 - lr: 0.0086\n",
      "Epoch 29/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 12.5867 - mae: 12.5867\n",
      "Epoch 29: val_loss improved from 11.53802 to 9.67360, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 414s 657ms/step - loss: 12.5867 - mae: 12.5867 - val_loss: 9.6736 - val_mae: 9.6736 - lr: 0.0086\n",
      "Epoch 30/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 12.1252 - mae: 12.1252\n",
      "Epoch 30: val_loss did not improve from 9.67360\n",
      "630/630 [==============================] - 404s 641ms/step - loss: 12.1252 - mae: 12.1252 - val_loss: 12.8627 - val_mae: 12.8627 - lr: 0.0086\n",
      "Epoch 31/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.9350 - mae: 11.9350\n",
      "Epoch 31: val_loss improved from 9.67360 to 9.61171, saving model to bone_age_weights.best.hdf5\n",
      "630/630 [==============================] - 404s 641ms/step - loss: 11.9350 - mae: 11.9350 - val_loss: 9.6117 - val_mae: 9.6117 - lr: 0.0086\n",
      "Epoch 32/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.7840 - mae: 11.7840\n",
      "Epoch 32: val_loss did not improve from 9.61171\n",
      "630/630 [==============================] - 402s 638ms/step - loss: 11.7840 - mae: 11.7840 - val_loss: 12.2895 - val_mae: 12.2895 - lr: 0.0086\n",
      "Epoch 33/250\n",
      "630/630 [==============================] - ETA: 0s - loss: 11.5579 - mae: 11.5579\n",
      "Epoch 33: val_loss did not improve from 9.61171\n",
      "630/630 [==============================] - 402s 638ms/step - loss: 11.5579 - mae: 11.5579 - val_loss: 11.7870 - val_mae: 11.7870 - lr: 0.0086\n",
      "Epoch 34/250\n",
      "231/630 [==========>...................] - ETA: 4:04 - loss: 12.0203 - mae: 12.0203"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/dense_1/MatMul/MatMul_1' defined at (most recent call last):\n    File \"c:\\program files\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\program files\\python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\program files\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\program files\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\program files\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GODIC\\AppData\\Local\\Temp/ipykernel_18720/2263790397.py\", line 1, in <module>\n      initalHistory = model.fit(train_dataset,\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense_1/MatMul/MatMul_1'\nOOM when allocating tensor with shape[131104,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense_1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18775]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18720/2263790397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m initalHistory = model.fit(train_dataset, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVALID_STEPS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense_1/MatMul/MatMul_1' defined at (most recent call last):\n    File \"c:\\program files\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\program files\\python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\program files\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\program files\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\program files\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GODIC\\AppData\\Local\\Temp/ipykernel_18720/2263790397.py\", line 1, in <module>\n      initalHistory = model.fit(train_dataset,\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"e:\\College and Courses\\College\\GRAD PROJECT\\newEnv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/dense_1/MatMul/MatMul_1'\nOOM when allocating tensor with shape[131104,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense_1/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_18775]"
     ]
    }
   ],
   "source": [
    "initalHistory = model.fit(train_dataset, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=250,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=VALID_STEPS,\n",
    "                    callbacks = callBacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78bcbf71713dd947ce2131f7f6689fb7d7a7279f673cc1a06b2b5cdb722ee962"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('newEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
