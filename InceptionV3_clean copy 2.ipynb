{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "from keras import Input\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Flatten, AveragePooling2D, concatenate\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from flow_dataframe import flow_from_dataframe\n",
    "\n",
    "# hyperparameters\n",
    "NUM_EPOCHS = 150\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE_TRAIN = 16\n",
    "BATCH_SIZE_VAL = 16\n",
    "\n",
    "\n",
    "# default size of InceptionResNetV2\n",
    "IMG_SIZE = (299, 299)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
    "\n",
    "core_idg = ImageDataGenerator(zoom_range=0.2,\n",
    "                              fill_mode='nearest',\n",
    "                              featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                              samplewise_center=False,  # set each sample mean to 0\n",
    "                              featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                              samplewise_std_normalization=False,  # divide each input by its std\n",
    "                              zca_whitening=False,  # apply ZCA whitening\n",
    "                              rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                              width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                              height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                              horizontal_flip=True,  # randomly flip images\n",
    "                              vertical_flip=False)\n",
    "\n",
    "val_idg = ImageDataGenerator(width_shift_range=0.25, height_shift_range=0.25, horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Generators\n",
    "### Reading RSNA Boneage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12611 images found of 12611 total\n",
      "train 10088 validation 2523\n",
      "flow_from_dataframe() -->\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 10088 images\n",
      "flow_from_dataframe() <--\n",
      "flow_from_dataframe() -->\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 2523 images\n",
      "flow_from_dataframe() <--\n"
     ]
    }
   ],
   "source": [
    "class_str_col = 'boneage'\n",
    "gender_str_col = 'male'\n",
    "\n",
    "base_bone_dir = os.path.join('rsna-bone-age')\n",
    "boneage_df = pd.read_csv(os.path.join(base_bone_dir, 'boneage-training-dataset.csv'))\n",
    "boneage_df['path'] = boneage_df['id'].map(lambda x: os.path.join(base_bone_dir,\n",
    "                                                         'boneage-training-dataset', \n",
    "                                                         'boneage-training-dataset', \n",
    "                                                         '{}.png'.format(x)))\n",
    "\n",
    "boneage_df['exists'] = boneage_df['path'].map(os.path.exists)\n",
    "print(boneage_df['exists'].sum(), 'images found of', boneage_df.shape[0], 'total')\n",
    "\n",
    "boneage_df[gender_str_col] = boneage_df[gender_str_col].map(lambda x: np.array([1]) if x else np.array([0])) # map boolean values to 1 and 0\n",
    "\n",
    "train_df_boneage, valid_df_boneage = train_test_split(boneage_df, test_size=0.2,\n",
    "                                                      random_state=2018)  # ,stratify=boneage_df['boneage_category'])\n",
    "print('train', train_df_boneage.shape[0], 'validation', valid_df_boneage.shape[0])\n",
    "\n",
    "train_gen_boneage = flow_from_dataframe(core_idg, train_df_boneage, path_col='path', y_col=class_str_col,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='rgb', batch_size=BATCH_SIZE_TRAIN)\n",
    "\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_gen_boneage = flow_from_dataframe(core_idg, valid_df_boneage, path_col='path', y_col=class_str_col,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='rgb',\n",
    "                                        batch_size=BATCH_SIZE_VAL)  # we can use much larger batches for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining callback functions and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"{}_weights.best.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,\n",
    "                            save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                      patience=15)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=15, verbose=1,\n",
    "                                   save_best_only=True, mode='auto', min_delta=0.0001, cooldown=5)\n",
    "\n",
    "optimizer = Adam(learning_rate = 0.007)\n",
    "\n",
    "\n",
    "def combined_generators(image_generator, gender_data, batch_size):\n",
    "    gender_generator = cycle(batch(gender_data, batch_size))\n",
    "    while True:\n",
    "        nextImage = next(image_generator)\n",
    "        nextGender = next(gender_generator)\n",
    "        nextGender=np.asarray(nextGender).astype(int)\n",
    "        assert len(nextImage[0]) == len(nextGender)\n",
    "        yield [nextImage[0], nextGender], nextImage[1]\n",
    "\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "train_gen_wrapper = combined_generators(train_gen_boneage, train_df_boneage[gender_str_col], BATCH_SIZE_TRAIN)\n",
    "val_gen_wrapper = combined_generators(valid_gen_boneage, valid_df_boneage[gender_str_col], BATCH_SIZE_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = Input(shape=(299, 299, 3), name='input_img')\n",
    "i2 = Input(shape=(1), name='input_gender')\n",
    "base = InceptionV3(input_tensor=i1, input_shape=(299, 299, 3), include_top=False, weights=None)\n",
    "\n",
    "feature_img = base.get_layer(name='mixed10').output\n",
    "feature_img = AveragePooling2D((2, 2))(feature_img)\n",
    "feature_img = Flatten()(feature_img)\n",
    "feature_gender = Dense(32, activation='relu')(i2)\n",
    "feature = concatenate([feature_img, feature_gender], axis=1)\n",
    "\n",
    "o = Dense(1000, activation='relu')(feature)\n",
    "o = Dense(1000, activation='relu')(o)\n",
    "o = Dense(1)(o)\n",
    "model = Model(inputs=[i1, i2], outputs=o)\n",
    "model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 17.5424 - mae: 17.5424\n",
      "Epoch 00001: val_loss improved from inf to 26.82191, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 855s 1s/step - loss: 17.5424 - mae: 17.5424 - val_loss: 26.8219 - val_mae: 26.8219 - lr: 0.0070\n",
      "Epoch 2/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 16.4147 - mae: 16.4147\n",
      "Epoch 00002: val_loss improved from 26.82191 to 21.15364, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 807s 1s/step - loss: 16.4147 - mae: 16.4147 - val_loss: 21.1536 - val_mae: 21.1536 - lr: 0.0070\n",
      "Epoch 3/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 16.4384 - mae: 16.4384\n",
      "Epoch 00003: val_loss improved from 21.15364 to 16.78942, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 812s 1s/step - loss: 16.4384 - mae: 16.4384 - val_loss: 16.7894 - val_mae: 16.7894 - lr: 0.0070\n",
      "Epoch 4/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 15.0110 - mae: 15.0110\n",
      "Epoch 00004: val_loss did not improve from 16.78942\n",
      "631/631 [==============================] - 819s 1s/step - loss: 15.0110 - mae: 15.0110 - val_loss: 26.7988 - val_mae: 26.7988 - lr: 0.0070\n",
      "Epoch 5/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 14.5891 - mae: 14.5891\n",
      "Epoch 00005: val_loss improved from 16.78942 to 16.49123, saving model to bone_age_weights.best.hdf5\n",
      "631/631 [==============================] - 768s 1s/step - loss: 14.5891 - mae: 14.5891 - val_loss: 16.4912 - val_mae: 16.4912 - lr: 0.0070\n",
      "Epoch 6/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 14.6317 - mae: 14.6317\n",
      "Epoch 00006: val_loss did not improve from 16.49123\n",
      "631/631 [==============================] - 819s 1s/step - loss: 14.6317 - mae: 14.6317 - val_loss: 18.9981 - val_mae: 18.9981 - lr: 0.0070\n",
      "Epoch 7/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 14.0713 - mae: 14.0713\n",
      "Epoch 00007: val_loss did not improve from 16.49123\n",
      "631/631 [==============================] - 802s 1s/step - loss: 14.0713 - mae: 14.0713 - val_loss: 21.7131 - val_mae: 21.7131 - lr: 0.0070\n",
      "Epoch 8/150\n",
      "631/631 [==============================] - ETA: 0s - loss: 14.3116 - mae: 14.3116\n",
      "Epoch 00008: val_loss did not improve from 16.49123\n",
      "631/631 [==============================] - 774s 1s/step - loss: 14.3116 - mae: 14.3116 - val_loss: 28.7977 - val_mae: 28.7977 - lr: 0.0070\n",
      "Epoch 9/150\n",
      "523/631 [=======================>......] - ETA: 1:43 - loss: 13.7918 - mae: 13.7918"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen_wrapper, validation_data=val_gen_wrapper,\n",
    "                              epochs=NUM_EPOCHS, steps_per_epoch=len(train_gen_boneage),\n",
    "                              validation_steps=len(valid_gen_boneage),\n",
    "                              callbacks=[early, reduceLROnPlat, checkpoint])\n",
    "\n",
    "model.save('./model_save_here/saved_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5898fd49d3a85f7f6a1728e6c8cd77fe1356b68e4a2df5dc09cb8f4bba0dc5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
